Automatically generated by Mendeley Desktop 1.19.5
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Lertpiriyasuwat2000,
abstract = {An industrial robot today uses measurements of its joint positions and models of its kinematics and dynamics to estimate and control its end-effector position. Substantially better end-effector position estimation and control performance would be obtainable if direct measurements of its end-effector position were also used. The subject of this paper is extended Kalman filtering for precise estimation of the position of the end-effector of a robot using, in addition to the usual measurements of the joint positions, direct measurements of the end-effector position. The estimation performances of extended Kalman filters are compared in applications to a planar two-axis robotic arm with very flexible links. The comparisons shed new light on the dependence of extended Kalman filter estimation performance on the quality of the model of the arm dynamics that the extended Kalman filter operates with.},
annote = {state estimation for end effector for robot with Flexible links

The authors uses extended kalman filter to estimate the position of the end effector of two axis robotic arm together with the joint measurement for highly flexible links in real time

UNCERTAINTY: the location of the end effector due to the flexible links 

SETUP: The authors use two link manipulator. Each joint has optical encoders and the end point has a reflective infrared-light emitter 

MODEL: The deflection of each links is modeled using the deflection beam model. 
The dynamic equations of the manipulator are derived from Kane's method.

LINEARIZATION: They linearixe the dynamic equation by eliminating the non-linear terms that involve the generalized elastic coordinates and their derivatives in the inertial matrix and the velocity vector. They coined the linearization method as a 'ruthless linearization'

The extended kalman filter is used to estimate the position of the end effector using the differential equation solution of the dynamic equation which was solved using Runge-Kutta method. 

Their result shows that with ruthlessly linearized model, the EKF can estimate the position of the end effector consistently during low-speed and high-speed slew maneuvers compared to continuosly linearized model of the dynamic model

THIS PAPER CAN BE USED AS AN ARGUMENT THAT LINEARIZATION OF MODEL BEFORE THE USE OF EKF AFFECTS THE PERFORMANCE OF THE FILTERING TECHNIQUE.},
author = {Lertpiriyasuwat, Vatchara and Berg, Martin C and Buffinton, Keith W},
doi = {10.1177/02783640022066851},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lertpiriyasuwat, Berg, Buffinton - 2000 - Extended Kalman Filtering Applied to a Two-Axis Robotic Arm with Flexible Links.pdf:pdf},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
keywords = {estimation,extended kalman filter,flexible},
number = {3},
pages = {254--270},
title = {{Extended Kalman Filtering Applied to a Two-Axis Robotic Arm with Flexible Links}},
url = {http://ijr.sagepub.com/content/19/3/254.abstract},
volume = {19},
year = {2000}
}
@inproceedings{Kamon1996,
abstract = {A scheme for learning to grasp objects using visual information is presented. The learning problem is divided into two separate subproblems: choosing grasping points and predicting the quality of a given grasp. For each grasp we store location parameters that code the locations of the grasping points, quality parameters that are relevant features for the assessment of grasp quality, and the associated grade. The location parameters, using a special coding which is not object specific, are used to locate grasping points on new target objects. A function from the quality parameters to the grade is learned from examples. Grasp quality for novel situations can be generalized and estimated using the learned function. An experimental setup using an AdeptOne manipulator was developed to test this scheme. The system had demonstrated an ability to grasp a relatively wide variety of objects, and its performance had significantly improved with practice following a small number of trials. The knowledge learned for a set of objects was successfully generalized to new objects},
annote = {DONT USE THIS PAPER{\textgreater} IT IS IN THIS LIST BECAUSE OF THE PAPER BY BUDIHARTO},
author = {Kamon, Ishay and Flash, T. and Edelman, S.},
booktitle = {Proceedings of IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.1996.506534},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kamon, Flash, Edelman - 1996 - Learning to grasp using visual information.pdf:pdf},
isbn = {0-7803-2988-0},
issn = {10504729},
number = {April},
pages = {2470--2476},
pmid = {506534},
title = {{Learning to grasp using visual information}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=506534},
year = {1996}
}
@article{Meeussen2007,
abstract = {This paper presents a contribution to programming by human demonstration, in the context of compliant-motion task specification for sensor-controlled robot systems that physically interact with the environment. One wants to learn about the geometric parameters of the task and segment the total motion executed by the human into subtasks for the robot, that can each be executed with simple compliant-motion task specifications. The motion of the human demonstration tool is sensed with a 3-D camera, and the interaction with the environment is sensed with a force sensor in the human demonstration tool. Both measurements are uncertain, and do not give direct information about the geometric parameters of the contacting surfaces, or about the contact formations (CFs) encountered during the human demonstration. The paper uses a Bayesian sequential Monte Carlo method (also known as a particle filter) to do the simultaneous estimation of the CF (discrete information) and the geometric parameters (continuous information). The simultaneous CF segmentation and the geometric parameter estimation are helped by the availability of a contact state graph of all possible CFs. The presented approach applies to all compliant-motion tasks involving polyhedral objects with a known geometry, where the uncertain geometric parameters are the poses of the objects. This work improves the state of the art by scaling the contact estimation to all possible contacts, by presenting a prediction step based on the topological information of a contact state graph, and by presenting efficient algorithms that allow the estimation to operate in real time. In real-world experiments, it is shown that the approach is able to discriminate in real time between some 250 different CFs in the graph},
annote = {This paper present an approach to generate a path planning by human demonstration for a sensor based manipulator. A tool containing optical markers are tracked during demonstration phase using a 3D vision sensor (a Krypton 6D Optical System). The tool is attached to a geometrically uncertain object in a controlled environment. 

The use of 3D vision sensor, and the estimation of the state of the tool and indirect estimation of force asserted by the tool based on the state of the tool introduce uncertainty. To compromise the uncertainty, the authors use particle filtering technique to estimate:
the pose and twist of the manipulated object via tracking of the manipulating tool 
the force between the contacting object

The researcher address their previous work on the same problem and optimize the particle filter with toplogical graph called contact-state graph to predict the next best configuration of the object being moved or contact formation. They observed that the contact-state graph reduce the number of particles used during sampling which decrease computational load and increase accuracy in their estimation. 

The paper however did not replicate their simulation in an experimentation with an actual manipulator},
author = {Meeussen, Wim and Rutgeerts, Johan and Gadeyne, Klaas and Bruyninckx, Herman and {De Schutter}, Joris},
doi = {10.1109/TRO.2007.892227},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meeussen et al. - 2007 - Contact-state segmentation using particle filters for programming by human demonstration in compliant-motion ta.pdf:pdf},
isbn = {15523098},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Bayesian estimation,Compliant motion,Human demonstration,Particle filter,Task segmentation},
number = {2},
pages = {218--231},
title = {{Contact-state segmentation using particle filters for programming by human demonstration in compliant-motion tasks}},
volume = {23},
year = {2007}
}
@article{Lightcap2010,
abstract = {Maximizing the tracking performance of an industrial manipulator requires an accurate expression of manipulator dynamics and efficient model parameterization. These objectives are difficult to achieve in manipulators with flexible joints since link positions typically are not measured. We present in this paper an extended Kalman filter (EKF) observer to estimate manipulator states and couple these estimates to an adaptive rigid-link flexible-joint (RLFJ) controller. In a computer simulation, the EKF-RLFJ controller demonstrated superior tracking performance compared to a traditional adaptive controller. Experimental results for the Mitsubishi PA10-6CE showed improvements in tracking performance using the EKF-RLFJ controller with a 5 kg end-effector payload. Even greater improvements in tracking performance may be achieved in manipulators with significant joint flexibility.},
annote = {This paper attempts to estimate the position of rigid links and flexible joint (RLFJ) manipulator using discrete-time extended Kalman Filter as an observer for the robot model and control system. 

The uncertainties of the link and the motors' dynamics are modeled into the manipulator's dynamic equations. The position of the links are nonlinear because of the flexibility of the manipulator's joints.

The authors stress that EKF has non-optimal estimation as is the case of any algorithm that requires linearization. They performed a simulation and reiterate their models and algorithm on a Mitsubishi PA10-6CE manipulator experimentally. They observed improved tracking performance for highly flexible joints (joints under high torque) and low tracking performance for rigid joints. Thus, the authors introduce a mixed rigid-joint/flexible joint model to the EKF-RLFL controller which improved the overall tracking performance.

This observation is also seen in Haghighipanal et al. (2016)},
author = {Lightcap, Chris A. and Banks, Scott A.},
doi = {10.1109/TCST.2009.2014959},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lightcap, Banks - 2010 - An extended kalman filter for real-time estimation and control of a rigid-link flexible-joint manipulator.pdf:pdf},
issn = {10636536},
journal = {IEEE Transactions on Control Systems Technology},
keywords = {Adaptive control,Extended Kalman filtering (EKF),Flexible-joint manipulators,Mitsubishi PA10-6CE},
number = {1},
pages = {91--103},
title = {{An extended kalman filter for real-time estimation and control of a rigid-link flexible-joint manipulator}},
volume = {18},
year = {2010}
}
@article{Um2013,
abstract = {We propose a SPAM (simultaneous planning and mapping) technique for a manipulator-type robot working in an uncertain environment via a novel Best Next Move algorithm. Demands for a smart decision to move a manipulator such as humanoid arms in uncertain or crowded environments call for a simultaneous planning and mapping technique. In the present work, we focus more on rapid map generation rather than global path search to reduce ignorance level of a given environment. The motivation is that the global path quality will be improved as the ignorance level of the unknown environment decreases. The 3D sensor introduced in the previous work has been improved for better mapping capability and the real-time rehearsal idea is used for {\'{i}} µ{\'{i}}±-space cloud point generation. Captured cloud points by 3D sensors, then, create an instantaneous {\'{i}} µ{\'{i}}±-space map whereby the Best Next Move algorithm directs the local motion of the manipulator. The direction of the Best Next Move utilizes the gradient of the density distribution of the {\'{i}} µ{\'{i}}±-nearest-neighborhood sets in {\'{i}} µ{\'{i}}±-space. It has a tendency of traveling along the direction by which the point clouds spread in space, thus rendering faster mapping of {\'{i}} µ{\'{i}}±-space obstacles possible. The proposed algorithm is compared with a sensor-based algorithm such as sensor-based RRT for performance comparison. Performance measures, such as mapping efficiency, search time, and total number of {\'{i}} µ{\'{i}}±-space point clouds, are reported as well. Possible applications include semiautonomous telerobotics planning and humanoid arm path planning.},
annote = {THIS SHOULD GO UNDER UNCERTAINTY IN UNKNOWN ENVIRONMENT

The paper present a simultaneous planning and mapping for a three degree of freedoom manipulator in an unknown environment. The paper argue that their method handle the uncertainty of the unknown environment by using virtual skin concept. The manipulator explores the environment using a mono-vision infrared proximity array (IPA) sensor which replicate the characteristic of a tactile-sensitive skin. From this exploration, the robot would model its configuration space (c-space) and use it as the input for their best-next-move algorithm to optimize path planning.The IPA sensors are attached on each links of the manipulator. Readers should note that an IPA sensor has limited range and noise bound output which add more uncertainty to the estimation of the manipulators c-space. 

The researcher address the noise in the sensor using group average feature (GAF). The point clouds generate from the IPA go through GAF algorithm to produce a more confident map of the c-space. 

The generated map of the c-space is used to provide motion planning for the robot manipulator. The rapidly-exploring random tree (RRT) path planning algorithm use the map as an input to plan the motion of the manipulator. The authors optimized the RRT algorithm with their best next move (BNM) algorithm. BNM is reactive and does not use any inverse kinematic solution. 

They validate the method using and compare the RRT-BNM method with RRT method by simulation and showed that the RRT-BNM method has higher mapping efficiency. They defined mapping efficiency as percentage of map built compared to the actual map, over the number of point clouds in the c-space. Due to the GAF decompression method, the RTT-BNM produce map with less point clouds. 
The author, however, did not repeat the RRT experimentally. 

THE PAPER DID NOT CONCERN WITH LINK POSITION ERROR 
Despite the higher efficiency of RTT-BNM path planning, the map produce does not represent an accurate geometric information of the unknown environment explored by the manipulator. I believe this is because there is a lack of pose estimation of the manipulators link since the research disregard the use of inverse kinematics, bayesian or non-bayesian filtering techniques to reconcile with the path planning.},
author = {Um, Dugan and Ryu, Dongseok},
doi = {10.5402/2013/679784},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Um, Ryu - 2013 - SPAM for a Manipulator by Best Next Move in Unknown Environments.pdf:pdf},
isbn = {9781467363587},
issn = {2090-8806},
journal = {ISRN Robotics},
number = {8},
pages = {5273--5278},
title = {{SPAM for a Manipulator by Best Next Move in Unknown Environments}},
url = {http://dx.doi.org/10.5402/2013/679784},
volume = {679784},
year = {2013}
}
@techreport{Dogar2010,
annote = {The paper uses contact during collision to estimate and improve robot's base localization where they use particle filters to improve the localization of the mobile platform (base of the robot) by taking into account the three dimensional lication of the contact during collision.

We observe that the approach is similar to haptic localization. However, the robot use the information to increast the certainty or accuracy of the robot pose in an unknown environment. However, the paper does not address the uncertainty at the manipulation level. We conclude that the authors only exploit information at the point of contact to ascertain the location of the robot in a kitchen environment.},
author = {Dogar, Mehmet and Hemrajani, Vishal},
booktitle = {Technology},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dogar, Hemrajani - 2010 - Proprioceptive Localization for Mobile Manipulators.pdf:pdf},
number = {February},
title = {{Proprioceptive Localization for Mobile Manipulators}},
year = {2010}
}
@article{Chotiprayanakul2007,
abstract = {I.A.A.R.C. - International Association for Automation and Robotics in Construction Civil Engineering},
author = {Chotiprayanakul, P. and Liu, D. K. and Wang, D. and Dissanayake, G.},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Skoglund et al. - 2010 - First Steps Towards a Robotic System for Flexible Volumetric Mapping of Indoor Environments(9).pdf:pdf},
isbn = {9788190423519},
journal = {ISARC Proceedings},
keywords = {3d-f 2,collision avoidance,force field},
title = {{A 3-Dimensional Force Field Method for Robot Collision Avoidance in Complex Environment}},
url = {http://www.iaarc.org/publications/proceedings{\_}of{\_}the{\_}24th{\_}isarc/a{\_}3dimensional{\_}force{\_}field{\_}method{\_}for{\_}robot{\_}collision{\_}avoidance{\_}in{\_}complex{\_}environment.html},
year = {2007}
}
@article{Kunz2010,
abstract = {We present a practical strategy for real-time path planning for articulated robot arms in changing environments by integrating PRM for Changing Environments with 3D sensor data. Our implementation on Care-O-Bot 3 identifies bottlenecks in the algorithm and introduces new methods that solve the overall task of detecting obstacles and planning a path around them in under 100 ms. A fast planner is necessary to enable the robot to react to quickly changing human environments. We have tested our implementation in real-world experiments where a human subject enters the manipulation area, is detected and safely avoided by the robot. This capability is critical for future applications in automation and service robotics where humans will work closely with robots to jointly perform tasks.},
annote = {This paper address changing in the workspace of a manipulator. They use dynamic roadmap (DRM) for path planning. They use midpoint workspace as workspace metric. They directly implement the point cloud from 3D sensor to check obstacle in a generate roadmap in a workspace. 

Preprocessing stage: The nodes of the roadmapts are created by sampling a 7-dimensional configuration space of the robot uniformly. These nodes are used to generate roadmaps from start to goal configuration. The initial generated roadmaps from these nodes are encapsulated with grid cells. 

Planning stage: During the planning stage, two search algorithm are used based on the predefined roadmaps. If an obstacle detected, via 3D sensor, near the grid cell that encapsulate the roadmap, or blocked part of the roadmap new path will be generated around the obstacle cell and new roadmaps are determined based on nodes that has been predetermined during preprocessing stage. To connect the start and the goal configuration of the manipulator, the authors use k nearest neighbors for each configuration

Experimentation setup: The authors use SwissRanger SR3000 with Care-O-bot 3. The preprocessing stage takes several hours but the the planning stage takes less than 100 ms to complete. The authors use two search algorithms to search the most optimal roadmap (least number of nodes), which are the A* and the Djikstra's algorithms. The authors conclude that A* search algorithm performs better thatn the Dijkstra algorithm when used with their methods of roadmap building.

We note that the path planning method used in this research only applicable for changes that involve static changes. However, despite being model based on largely open space, the authors remarked that their algorithm performs well even when the obtacles introduce narrow space roadmaps.},
author = {Kunz, Tobias and Reiser, Ulrich and Stilman, Mike and Verl, Alexander},
doi = {10.1109/IROS.2010.5653275},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kunz et al. - 2010 - Real-time path planning for a robot arm in changing environments.pdf:pdf},
isbn = {9781424466757},
issn = {2153-0858},
journal = {IEEE/RSJ 2010 International Conference on Intelligent Robots and Systems, IROS 2010 - Conference Proceedings},
keywords = {Path Planning for Manipulators,Service Robots},
pages = {5906--5911},
title = {{Real-time path planning for a robot arm in changing environments}},
year = {2010}
}
@inproceedings{Burns2007,
abstract = {Sampling-based algorithms have dramatically improved the state of the art in robotic motion planning. However, they make restrictive assumptions that limit their applicability to manipulators operating in uncontrolled and partially unknown environments. This work describes how one of these assumptions - that the world is perfectly known - can be removed. We propose a utility-guided roadmap planner that incorporates uncertainty directly into the planning process. This enables the planner to identify configuration space paths that minimize uncertainty and, when necessary, efficiently pursue further exploration through utility-guided sensing of the workspace. Experimental results indicate that our utility-guided approach results in a robust planner even in the presence of significant error in its perception of the workspace. Furthermore, we show how the planner is able to reduce the amount of required sensing to compute a successful plan},
annote = {This paper present a method of sample-based motion planning on top of an occupancy grid map. The sampling-based planner take regard the uncertainty of sensor measurements and incorporate the uncertainty into the occupancy grid map. Their method is iterative; the planner consider and incomplete information about the world and constantly update changes in their map model and configuration space. 

The authors use the concept of utility and cost to weight the probability of an edge. A* algorithm is used to search the most optimal path from randomly sampled node in the configuration space. During edge validation of the roadmap is witheld before the A* algorithm complete its query. 

They validate their planner by simulating three seperate experiments, two of which, involve manipulators with ten degrees of freedom and fourteen degrees of freedom respectively. The planner is specified to solve 50 planning queries given a start and a goal configurations.

They report that building a planner on top of a occupancy grid map increase the accuracy of completing the path from the start configuration to the goal configuration. They conclude that, compared to PRM, their method able to eliminate the possibility of invalid edges in their roadmap because they introduce error model of the sensor at hand.},
author = {Burns, Brendan and Brock, Oliver},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2007.363984},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burns, Brock - 2007 - Sampling-based motion planning with sensing uncertainty.pdf:pdf},
isbn = {1424406021},
issn = {10504729},
number = {April},
pages = {3313--3318},
title = {{Sampling-based motion planning with sensing uncertainty}},
year = {2007}
}
@article{Ulrich2011,
annote = {1. this paper propose the use of extended kalman filter to estimate joint positions and velocities for flexibel joint positions and velocities for flexible joint space robotic manipulator

1.2 joint flexibility in manipulators for space robots are pronouces because they are light-weigth

3. They extend the design of extended kalman filters (EKF) based on nonlinear joint models for use with an adaptive controller combinations. By using this combination, they increase the accuracy of the closed-loop estimation and control of a flexible joint space robot.

4. Their uncertainty comes from the nonlinearity behavior of the flexible joint of their space robots

5. Although nonlinear joints can be approximated by representing joint flexibility by a linear spring spring, the author of this paper argues that such assumption is inaccurate, thus, adding these effects to their nonlinear joint models
-nonlinear stiffness 
-soft-windup
-frictional loses
-inertial cross-coupling

6. They presented a converging error for a non-linear based EKF technique used with linear and nonlinear joint model. However, the error diverges for linear based EKF techniques with the same model coupling.},
author = {Ulrich, Steve},
doi = {10.1109/ACC.2011.5990848},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ulrich - 2011 - Extended Kalman filtering for flexible joint space robot control.pdf:pdf},
isbn = {9781457700811},
journal = {American Control Conference},
pages = {1021--1026},
title = {{Extended Kalman filtering for flexible joint space robot control}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5990848},
year = {2011}
}
@article{Costa2015,
abstract = {—Autonomous robots play a pivotal role in improving productivity and reducing operational costs. They excel at both precision and speed in repetitive jobs and can cooperate with humans in complex tasks within dynamic environments. Self-localization is critical to any robot that must navigate or manipulate the environment. To solve this problem, a modular localization system suitable for mobile manipulators was developed. By using LIDAR data the proposed system is capable of achieving less than a centimeter in translation error and less than a degree in rotation error while requiring only 5 to 25 milliseconds of processing time. The system was tested in two different robot platforms at different velocities and in several cluttered and dynamic environments. It demonstrated high accuracy while performing pose tracking and high reliability when estimating the initial pose using feature matching. No artificial landmarks are required and it is able to adjust its operation rate in order to use very few hardware resources when a mobile robot is not moving.},
annote = {Mobile robot problems 

The journal contain alot at ROS information for beginners},
author = {Costa, Carlos M. and Sobreira, H{\'{e}}ber M. and Sousa, Armando J. and Veiga, Germano M.},
doi = {10.1109/ICIT.2015.7125588},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Costa et al. - 2015 - Robust and accurate localization system for mobile manipulators in cluttered environments.pdf:pdf},
isbn = {9781479977994},
journal = {Proceedings of the IEEE International Conference on Industrial Technology},
keywords = {Iterative Closest Point,Normal Distributions Transform,Point Cloud Library,Robot Operating System,Self-localization,feature matching,initial pose estimation,point cloud registration,pose tracking},
number = {June},
pages = {3308--3313},
title = {{Robust and accurate localization system for mobile manipulators in cluttered environments}},
volume = {2015-June},
year = {2015}
}
@article{Pilania2015,
abstract = {We present a hierarchical and adaptive mobile manipulator planner (HAMP) that plans for both the base and the arm in a judicious manner---allowing the manipulator to change its configuration autonomously when needed if the current arm configuration is in collision with the environment as the mobile manipulator moves along the planned path. This is in contrast to current implemented approaches that are conservative and fold the arm into a fixed home configuration. Our planner first constructs a base roadmap and then for each node in the roadmap it checks for collision status of current manipulator configuration along the edges formed with adjacent nodes, if the current manipulator configuration is in collision, the manipulator C-space is searched for a new reachable configuration such that it is collision-free as the mobile manipulator moves along the edge and a path from current configuration to the new reachable configuration is computed. We show that HAMP is probabilistically complete. We compared HAMP with full 9D PRM and observed that the full 9D PRM is outperformed by HAMP in each of the performance criteria, i.e., computational time, percentage of successful attempts, base path length, and most importantly, undesired motions of the arm. We also evaluated the tree versions of HAMP, with RRT and bi-directional RRT as core underlying sub-planners, and observed similar advantages, although the time saving for bi-directional RRT version is modest. We then present an extension of HAMP (we call it HAMP-U) that uses belief space planning to account for localization uncertainty associated with the mobile base position and ensures that the resultant path for the mobile manipulator has low uncertainty at the goal. Our experimental results show that the paths generated by HAMP-U are less likely to result in collision and are safer to execute than those generated by HAMP (without incorporating uncertainty), thereby showing the importance of incorporating base pose uncertainty in our overall HAMP algorithm.},
annote = {They propose a method of base uncertainty by using their novel hierarchical and adaptive mobile manipulator planner uncertainty called HAMP-U to account for the uncertainty of the base of a mobile robot},
author = {Pilania, Vinay and Gupta, Kamal},
doi = {10.1007/s10514-015-9427-2},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pilania, Gupta - 2015 - A hierarchical and adaptive mobile manipulator planner with base pose uncertainty.pdf:pdf},
isbn = {9781479971749},
issn = {15737527},
journal = {Autonomous Robots},
keywords = {Adaptive,Mobile manipulation,Motion planning,Navigation,Planning under uncertainty},
number = {1},
pages = {65--85},
publisher = {Springer US},
title = {{A hierarchical and adaptive mobile manipulator planner with base pose uncertainty}},
url = {http://dx.doi.org/10.1007/s10514-015-9427-2},
volume = {39},
year = {2015}
}
@article{Guibas2010,
abstract = {Motion planning under uncertainty is an important problem in robotics. Although probabilistic sampling is highly successful for motion planning of robots with many degrees of freedom, sampling-based algorithms typically ignore uncertainty during planning. We introduce the notion of a bounded uncertainty roadmap (BURM) and use it to extend sampling-based algorithms for planning under uncertainty in environment maps. The key idea of our approach is to evaluate uncertainty, represented by collision probability bounds, at multiple resolutions in different regions of the configuration space, depending on their relevance for finding a best path. Preliminary experimental results show that our approach is highly effective: our BURM algorithm is at least 40 times faster than an algorithm that tries to evaluate collision probabilities exactly, and it is not much slower than classic probabilistic roadmap planning algorithms, which ignore uncertainty in environment maps.},
annote = {Mobile robot application
DO NOT USE},
author = {Guibas, Leonidas J. and Hsu, David and Kurniawati, Hanna and Rehman, Ehsan},
doi = {10.1007/978-3-642-00312-7_13},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Skoglund et al. - 2010 - First Steps Towards a Robotic System for Flexible Volumetric Mapping of Indoor Environments(3).pdf:pdf},
isbn = {9783642003110},
issn = {16107438},
journal = {Springer Tracts in Advanced Robotics},
pages = {199--215},
title = {{Bounded uncertainty roadmaps for path planning}},
volume = {57},
year = {2010}
}
@article{Miseikis2017,
abstract = {—With advancing technologies, robotic manipulators and visual environment sensors are becoming cheaper and more widespread. However, robot control can be still a limiting factor for better adaptation of these technologies. Robotic manipulators are performing very well in structured workspaces, but do not adapt well to unexpected changes, like people entering the workspace. We present a method combining 3D Camera based workspace mapping, and a predictive and reflexive robot manipulator trajectory estimation to allow more efficient and safer operation in dynamic workspaces. In experiments on a real UR5 robot our method has proven to provide shorter and smoother trajectories compared to a reactive trajectory planner in the same conditions. Furthermore, the robot has successfully avoided any contact by initialising the reflexive movement even when an obstacle got unexpectedly close to the robot. The main goal of our work is to make the operation more flexible in unstructured dynamic workspaces and not just avoid obstacles, but also adapt when performing collaborative tasks with humans in the near future.},
annote = {Mapping by Octomap

The author use the background of shared human-robot workspace as their problem statement. 
Method: Point clouds from the cameras are pre-processed using Statisitcal Outlier Removal algorithm to reject outliers. They proceed by merging point cloud data from two 3D cameras (Kinect Sensor) using iterative closest point. Iterative closest point (ICP) is often used in mobile robot to combine two scans collected at different position together. They use forward kinematic to assist in replacing point clouds corresponding to the robots chassis with cylindrical shapes. The map of the environment are model using octomap and embedded each grid cell with a decaying occupancy value. The decaying cost value are used to represent danger zone, a mediary zone, and a non-danger zone in the map for a reflexive and predictive behaviors. Building their path planning on top of these map provde a responsive motion even if the robot workspace is populated by moving objects. 


setup: the authors uses 6DOF UR5 robot. The authors adopt a eye-to-hand approach.

validation: they validate their method by simulating a predifined back and forth motion between a start configuration and a goal configuration. The first simulation act as the baseline or the benchmark of their path planning approach using only Rapidly-exploring Random Trees (RRT). The second and the third experiments introduce a moving object into the robot's workspace but a reactive path planning and the reflexive-predictive path planning approaches are used respectively. They concluded that although experiments 3 performs at the shortest time, the result was not significant. 

ICP use in this method is computationally expensive because it involves direct point clouds.},
archivePrefix = {arXiv},
arxivId = {1610.03646},
author = {Miseikis, Justinas and Glette, Kyrre and Elle, Ole Jakob and Torresen, Jim},
doi = {10.1109/SSCI.2016.7850237},
eprint = {1610.03646},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miseikis et al. - 2017 - Multi 3D camera mapping for predictive and reflexive robot manipulator trajectory estimation.pdf:pdf},
isbn = {9781509042401},
journal = {2016 IEEE Symposium Series on Computational Intelligence, SSCI 2016},
title = {{Multi 3D camera mapping for predictive and reflexive robot manipulator trajectory estimation}},
year = {2017}
}
@article{Pomarlan2013,
annote = {not using this in the review},
author = {Pomarlan, Mihai and Sucan, Ioan A.},
doi = {10.1109/CINTI.2013.6705245},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pomarlan, Sucan - 2013 - Motion planning for manipulators in dynamically changing environments using real-time mapping of free workspace.pdf:pdf},
isbn = {9781479901975},
journal = {CINTI 2013 - 14th IEEE International Symposium on Computational Intelligence and Informatics, Proceedings},
keywords = {dynamic environments,robot motion planning,sparse roadmaps},
pages = {483--487},
title = {{Motion planning for manipulators in dynamically changing environments using real-time mapping of free workspace}},
year = {2013}
}
@article{Rigatos2009,
annote = {THIS PAPER IS GOOD FOR AN INTRODUCTION FOR PF

The paper describe particle filter by fusing data from an IMU and joint encoders to estimating pose of the end effector.

The purpose of this paper is to estimate the state vector of a three degree of freedom industrial robot 
using accelerometer and an encoder for each joint. The estimated state vector is used to generate appropriate control signal for the manipulators

Accelerometer are notorious for being nonlinear. Also, with encoder as the primary feedback for joint measurements, the state of the manipulator becomes non-linear and uncertain. The uncertainty introduced from the sensors and the link material are managed using particle filtering technique.

The authors use particle filter to perform data fusion between an accelerometer and an encoder to estimate the pose of the end effector. Readers should note that both accelerometers and encoders has non-gaussian behavior. This is more pronounce if the joints are flexible which introduce nonlinearity to the state (position of the end effector) of the manipulator.

Particle filter is used simply because it is nonparametric. This mean that the parameter of a normal distribution are not assumed. Instead, PF perform the estimation based on the sampled data and generate the distribution from these samples. The method of sampling provide a general solution that has no presumption of sensor characteristics. This also means that with particle filters, more accessable sensors such as an accelerometer or an IMU can be used without scaling down accuracy. 

The state vector estimation was compared with extended kalman filtering technique. The authors observe higher accuracy in estimation of the state vector for PF compared to EKF technique. However, the author caution the selection of particles numbers may improve accuracy with the expense of computational load.},
author = {Rigatos, G.G.},
doi = {10.1109/TIM.2009.2021212},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rigatos - 2009 - Particle Filtering for State Estimation in Nonlinear Industrial Systems.pdf:pdf},
issn = {0018-9456},
journal = {IEEE Transactions on Instrumentation and Measurement},
number = {11},
pages = {3885--3900},
title = {{Particle Filtering for State Estimation in Nonlinear Industrial Systems}},
url = {http://ieeexplore.ieee.org/document/5184922/},
volume = {58},
year = {2009}
}
@article{Lippiello2004,
abstract = { An algorithm for the visual estimation of the pose of a moving object is presented in this paper. The algorithm exploits the prediction capability of the extended Kalman Filter to realize in real time a dynamic optimal selection of the object image features used for pose estimation. The robustness of the system with respect to the measurement noise and modelling errors is enhanced by using an adaptive scheme. Experimental case studies are presented to prove the effectiveness of the proposed approach.},
annote = {KIV},
author = {Lippiello, V. and Siciliano, B. and Villani, L.},
doi = {10.1109/IROS.2004.1389476},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lippiello, Siciliano, Villani - 2004 - Visual motion estimation of 3D objects an adaptive extended Kalman filter approach.pdf:pdf},
isbn = {0-7803-8463-6},
journal = {2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)},
pages = {957--962},
title = {{Visual motion estimation of 3D objects: an adaptive extended Kalman filter approach}},
volume = {1},
year = {2004}
}
@article{Li2017,
annote = {KIV this paper:
Is this active SLAM? The terminology is in a mess.},
author = {Li, Leiyuan and Hu, Yanzhu},
doi = {10.1177/1729881417734829},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Hu - 2017 - Autonomous positioning control of manipulator and fast surface fitting based on particle filter and point cloud library.pdf:pdf},
issn = {17298814},
journal = {International Journal of Advanced Robotic Systems},
keywords = {Autonomous positioning,BP neural network,Manipulator,Particle filter,Point cloud library},
number = {5},
pages = {1--14},
title = {{Autonomous positioning control of manipulator and fast surface fitting based on particle filter and point cloud library technology}},
volume = {14},
year = {2017}
}
@article{Song2013,
abstract = {This paper presents a mobile manipulation and visual servoing design for a configurable mobile manipulator by using a Kinect sensor. To achieve this goal, an image-based grasping design is combined with a visual simultaneous localization and mapping (vSLAM). The proposed vSLAM method is based on extended Kalman filter (EKF) and a Kinect RGBD sensor. In the manipulator design, the robot arms are designed to be able to configure as a handrail for user support in execution of walking assistance tasks. The purpose of this design is to perform mobile manipulation and walking assistance tasks on the same robot. Experiments on the prototype dual-arm mobile manipulator validate that the proposed method can find and grasp a target object after navigation a distance to the object position. After the robot delivered the object to the user, it configured to provide walking assist to the user using the suggested compliance controller.},
annote = {This paper present two problems and two solutions. One is on self localization, a SLAM problem which they solved using EKF-SLAM and the other is on grasping problem. We will only regard the grasping problem since it directly involve manipulation under uncertainty. They use Speed Up Robust Feature (SURF) for object identification and visual servoing using Position-based Visual Servoing (PBVS) to grasp an object and return the object to a person. 

During object identification, the authors raised the concern of matching error during identification which may result in misleading object recognition. They mitigate the problem using random sample consensus algorithm (RANSAC) to reject outliers adn to find the homography matrix. Homography matrix transforms points in one image to the corresponding points in another image when a camera changes in position.

The result of their investigation suggest a successful object retriaval to a person. They did not, however, present any comparison of their result with other approach for the Grasping problem.},
author = {Song, Kai Tai and Jiang, Sin Yi and Wu, Ching Jui and Lin, Ming Han and Wu, Cheng Hei and Chiu, Yi Fu and Lin, Chia How and Lin, Chao Yu and Liu, Chien Hung},
doi = {10.1109/CACS.2013.6734139},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Song et al. - 2013 - Mobile manipulation and visual servoing design of a configurable mobile manipulator.pdf:pdf},
isbn = {9781479923847},
journal = {2013 CACS International Automatic Control Conference, CACS 2013 - Conference Digest},
pages = {239--244},
title = {{Mobile manipulation and visual servoing design of a configurable mobile manipulator}},
year = {2013}
}
@article{Babiarz2014,
annote = {KIV: WHERE TO PUT THIS?},
author = {Babiarz, Artur and Klamka, Jerzy and Zawiski, Radoslaw and Niezabitowski, Michal},
doi = {10.1109/ICCA.2014.6871049},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Babiarz et al. - 2014 - An approach to observability analysis and estimation of human arm model.pdf:pdf},
isbn = {978-1-4799-2837-8},
issn = {19483457},
journal = {11th IEEE International Conference on Control {\&} Automation (ICCA)},
pages = {947--952},
title = {{An approach to observability analysis and estimation of human arm model}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6871049},
year = {2014}
}
@article{Gasparri2006,
abstract = {A multirobot system composed by a five DoF manipulator (SCORTEC-ER 1) and a mobile base (ATRV-Jr by iRobot) is considered. The system is equipped with uniform software architecture able to control the motion of both components. Some exteroceptive sensors like sonars and laser rangefinders are available on the mobile platform, some others are mounted on the end-effector of the manipulator: a colour camera, able to locate objects to operate with; an ultrasound range finder, near the camera, that will be used to get distance measures. In this paper we consider the problem of relocalising the mobile manipulator in a known environment supposing that no base movement is allowed to avoid hazard operations. As only the arm can be safely panned to explore the surroundings, the proposed procedure is based exclusively on the ultrasound rangefinder. Using such measures, and making the hypothesis that the arm configuration in known, a Monte Carlo filter is designed to estimate the base pose. Such multiple hypotheses filter is appropriate in this kind of problems where, in the best case, it is possible to retrieve a finite number of possible poses compatible with available measures},
annote = {NO UNCERTAINTY MANAGEMENT AT MANIPULATION LEVEL

USE AS AN EXAMPLE OF MANIPULATOR ON A MOBILE PLATFORM},
author = {Gasparri, a. and Panzieri, S. and Pascucci, F. and Ulivi, G.},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gasparri et al. - 2006 - Pose recovery for a mobile manipulator using a particle filter.pdf:pdf},
journal = {2006 14th Mediterranean Conference on Control and Automation},
title = {{Pose recovery for a mobile manipulator using a particle filter}},
year = {2006}
}
@article{Wang2017,
abstract = {Obstacle detection plays an important role for robot collision avoidance and motion planning. This paper focuses on the study of the collision prediction of a dual-arm robot based on a 3D point cloud. Firstly, a self-identification method is presented based on the over-segmentation approach and the forward kinematic model of the robot. Secondly, a simplified 3D model of the robot is generated using the segmented point cloud. Finally, a collision prediction algorithm is proposed to estimate the collision parameters in real-time. Experimental studies using the Kinect sensor and the Baxter robot have been performed to demonstrate the performance of the proposed algorithms.},
annote = {This paper present a method using point clouds to perform self-identification using k-means clustering method and obstacle detection and obstacle avoidance.

The point cloud are used to generate the skeleton and the sphere along the skeleton. The point clouds are sparse and noisy which introduce uncertaity to the self-identification. However, the uncertainty is eliminated using a filter based on the density of the point cloud

The detection of the obstacles are based on the negation of point clouds that are not a part of the skeleton and the sphere that shape the manipulator. This segmentation is the based of their approach to obstacle avoidance.

They tested their algorithm by performing three experiments sequentially using a Baxter manipulator robot with eye in hand configuration. These experiments involve the validation of their self-identification algorithm, obstacle detection algorithm, and obstacle avoidance algorithm. They compare their approach with another work by Rakprayoon et al. (2011) Kinect-based 
obstacle detection for manip-ulator. They report that their method manage to avoid collision even when the obstacle is close to the robot and eliminate unnecessary movements for obstacles far from the manipulator.},
author = {Wang, Xinyu and Yang, Chenguang and Ju, Zhaojie and Ma, Hongbin and Fu, Mengyin},
doi = {10.1007/s11042-016-3275-8},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2017 - Robot manipulator self-identification for surrounding obstacle detection.pdf:pdf},
isbn = {1380-7501},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Collision prediction,Manipulator self-identification,Point cloud,Superpixel},
number = {5},
pages = {6495--6520},
title = {{Robot manipulator self-identification for surrounding obstacle detection}},
volume = {76},
year = {2017}
}
@article{Sun2016,
annote = {The authors use large scale direct mono-SLAM (LSD-SLAM) technique to replicate the motion of an human operator.
The technique resolve the noise from their measurements usinf dbscan, a density-based spatial clustering algorithm, to eliminate outlier. 

LSD-SLAM use a visual camera to produce point clouds with the help of dbscan algorithm. The scenes generated from the camera are three dimensional. However, the movement of the manipulator is planar. The LSD-SLAM is used to replicate the movement of a human arm. The movement are learned and modeled using Gaussian Mixture Model (GMM) and the parameters of the model are estimated using Gaussian Mixture Regression (GMR). GMM is a probabilistic model that assume all the data points are generated from a mixture of finite number of Gaussian distribution with unknown parameters. GMR uses Expectation maximization iterative learning algorithm to help replicate an output data based on an input. We observe that, by using GMM and GMR, the authors manage to handle the movement uncertainty of the human operator and map the movement into a planar actuation of the manipulator.

The authors perform an experiment by recording the movement of the human operator. The LSD-SLAM manage to generate a smooth path for the end effector of the manipulator as prescribed by the GMM and GMR based on the demonstration of the operator.},
author = {Sun, Peng and Chen, Jie and Lau, Henry Y.K.},
doi = {10.1109/ROBIO.2016.7866539},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun, Chen, Lau - 2016 - Programming human-like point-to-point approaching movement by demonstrations with Large-Scale Direct Monocular S.pdf:pdf},
isbn = {9781509043644},
journal = {2016 IEEE International Conference on Robotics and Biomimetics, ROBIO 2016},
pages = {1498--1503},
title = {{Programming human-like point-to-point approaching movement by demonstrations with Large-Scale Direct Monocular SLAM}},
year = {2016}
}
@article{Wang1997,
author = {Wang, Youbing and Huang, Shoudong},
doi = {10.1109/ICARCV.2014.7064596},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Huang - 1997 - Towards dense moving object segmentation based robust dense RGB-D SLAM in dynamic scenarios.pdf:pdf},
isbn = {9781479951994},
journal = {2014 13th International Conference on Control Automation Robotics and Vision, ICARCV 2014},
keywords = {RGB-D SLAM,motion segmentation,moving object segmentation,robustness},
number = {December},
pages = {1841--1846},
title = {{Towards dense moving object segmentation based robust dense RGB-D SLAM in dynamic scenarios}},
volume = {2014},
year = {1997}
}
@article{Hu2017,
annote = {The paper address force estimation for human compliant manipulator. The authors use inverse dynamic model (IDM) as a prior to the force. The approach also model the sensor using rigid body dynamic 

The only feedback data used as update state of their novel disturbance Kalman Filter are the joint positions and the torque measurement from the sensor.

The Disturbance Kalman filter takes into account the uncertainty from the disturbance dynamics

The authors successfully implement the DKF for the force estimation technique on a six degree of freedom Kinova Jaco2 arm robot.},
author = {Hu, Jin and Xiong, Rong},
doi = {10.1109/TIE.2017.2748056},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu, Xiong - 2017 - Contact Force Estimation for Robot Manipulator Using Semi-parametric Model and Disturbance Kalman Filter.pdf:pdf},
issn = {0278-0046},
number = {c},
title = {{Contact Force Estimation for Robot Manipulator Using Semi-parametric Model and Disturbance Kalman Filter}},
volume = {0046},
year = {2017}
}
@article{Paul2011,
abstract = {This paper presents a system for Autonomous eXploration to Build A Map (AXBAM) of an unknown, 3D complex steel bridge structure using a 6 degree-of-freedom anthropomorphic robot manipulator instrumented with a laser range scanner. The proposed algorithm considers the trade-off between the predicted environment information gain available from a sensing viewpoint and the manipulator joint angle changes required to position a sensor at that viewpoint, and then obtains collision-free paths through safe, previously explored regions. Information gathered from multiple viewpoints is fused to achieve a detailed 3D map. Experimental results show that the AXBAM system explores and builds quality maps of complex unknown regions in a consistent and timely manner. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
annote = {The paper present a path planning strategy to perform autonomous grit-blasting as a part of bridge maintenance process. They developed a framework called Autonomous eXploration to BUild a Map (AXBAM). AXBAM define the uncertainty in an unknown environment as the measurement of information that has not been discovered in the environment by using Shanon's entropy definition of information theory. This is an appropriate concept to use in modeling an unknown environment since the theory help in optimizing the exploration and path planning of a manipulator. The authors use Occupancy Grid map concept to handle uncertainty for path plannin in the unknown environment based on the entropy definition. The authors implement ellipsoid force-field planner to plan collision free roadmap. 

Another problem addressed by the authors states that there are possibilities for multiple goal configuration and use their entropy model to arrive to a single goal configuration with the highest information gain prediction. 

Despite the use of occupancy map in managing the control of their manipulator under uncertain environment, the mapping model in this paper uses direct point clouds for detailed geometric representation of the unknown environment. However, the author fails to show any optimization of registrating local scans into a global scans. We believe without this optimization, if the pose of the end effector is uncertain, their map may have diverging misalignment. 

The authors uses Hokuyo Laser Range Finder (Hokuyo URG-04LX) as a scanning sensor attached on a six degrees of freedom Denso VM-6093 manipulator arm with eye-in-hand configuration. The 5th joint rotates to facilitate the intial scanning of the environment before exploration commence. Based on this intial scan, the robot will start exploring. By using AXBAM, the authors claim to reduce computation in decision making during exploration.},
author = {Paul, Gavin and Webb, Stephen and Liu, Dikai and Dissanayake, Gamini},
doi = {10.1016/j.robot.2011.04.001},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paul et al. - 2011 - Autonomous robot manipulator-based exploration and mapping system for bridge maintenance.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {3D mapping,Bridge maintenance,Exploration,Laser range scanning,Robot manipulator},
number = {7-8},
pages = {543--554},
publisher = {Elsevier B.V.},
title = {{Autonomous robot manipulator-based exploration and mapping system for bridge maintenance}},
url = {http://dx.doi.org/10.1016/j.robot.2011.04.001},
volume = {59},
year = {2011}
}
@article{Garcia2007,
abstract = {This article surveys traditional research topics in industrial robotics and mobile robotics and then expands on new trends in robotics research that focus more on the interaction between human and robot. The new trends in robotics research have been denominated service robotics because of their general goal of getting robots closer to human social needs, and this article surveys research on service robotics such as medical robotics, rehabilitation robotics, underwater robotics, field robotics, construction robotics and humanoid robotics. The aim of this article is to provide an overview of the evolution of research topics in robotics from classical motion control for industrial robots to modern intelligent control techniques and social learning paradigms, among other aspects},
author = {Garcia, Elena and Jimenez, Maria Antonia and {De Santos}, Pablo Gonzalez and Armada, Manuel},
doi = {10.1109/MRA.2007.339608},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garcia et al. - 2007 - The evolution of robotics research.pdf:pdf},
isbn = {1070-9932 VO - 14},
issn = {10709932},
journal = {IEEE Robotics and Automation Magazine},
keywords = {Field robots,Humanoid robots,Industrial robots,Medical robots,Mobile robots,Rehabilitation robots,Robtoics,Service robots,Underwater robots,Walking robotsservice robots},
number = {1},
pages = {90--103},
title = {{The evolution of robotics research}},
volume = {14},
year = {2007}
}
@article{Das2016,
abstract = {Multi-camera clusters used for visual SLAM assume a fixed calibration between the cameras, which places many limitations on its performance, and directly excludes all configurations where a camera in the cluster is mounted to a moving component. In this work, we present a calibration method for dynamic multi-camera clusters, where one or more of the cluster cameras is mounted to an actuated mechanism, such as a gimbal or robotic manipulator. Our calibration approach parametrizes the actuated mechanism using the Denavit-Hartenberg convention, then determines the calibration parameters which allow for the estimation of the time varying extrinsic transformations between camera frames. We validate our calibration approach using a dynamic camera cluster consisting of a static camera and a camera mounted to a pan-tilt unit, and demonstrate that the dynamic camera cluster can provide accurate tracking when used to perform SLAM.},
annote = {KIV},
author = {Das, Arun and Waslander, Steven L.},
doi = {10.1109/IROS.2016.7759682},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Das, Waslander - 2016 - Calibration of a dynamic camera cluster for multi-camera visual SLAM.pdf:pdf},
isbn = {9781509037629},
issn = {21530866},
journal = {IEEE International Conference on Intelligent Robots and Systems},
number = {Cmm},
pages = {4637--4642},
title = {{Calibration of a dynamic camera cluster for multi-camera visual SLAM}},
volume = {2016-Novem},
year = {2016}
}
@inproceedings{Torabi2007,
abstract = {The concept of C-space entropy for sensor-based exploration and view planning for general robot-sensor systems has been introduced in [?], [?], [?], [?]. The robot plans the next sensing action (also called the next best view) to maximize the expected C-space entropy reduction, (known as Maximal expected Entropy Reduction, or MER). It gives priority to those areas that increase the maneuverable space around the robot, taking into account its physical size and shape, thereby facilitating reachability for further views. However, previous work had assumed a Poisson point process model for obstacle distribution in the physical space, a simplifying assumption. In this paper we derive an expression for MER criterion assuming an occupancy grid map, a commonly used representation for workspace representation in much of the mobile robot community. This model is easily obtained from typical range sensors such as laser range finders, stereo vision, etc., and furthermore, we can incorporate occlusion constraints and their effect in the MER formulation, making it more realistic. Simulations show that even for holonomic mobile robots with relatively simple geometric shapes (such as a rectangle), the MER criterion yields improvement in exploration efficiency (number of views needed to explore the C-space) over physical space based criteria.},
annote = {Use this paper in introduction to your map approach to uncertainty management},
author = {Torabi, Lila and Kazemi, Moslem and Gupta, Kamal},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2007.4399451},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Torabi, Kazemi, Gupta - 2007 - Configuration space based efficient view planning and exploration with occupancy grids.pdf:pdf},
isbn = {1424409128},
keywords = {C-space entropy,Occupancy grid model,Sensor-based path planning,View planning},
pages = {2827--2832},
title = {{Configuration space based efficient view planning and exploration with occupancy grids}},
year = {2007}
}
@article{Du2014a,
abstract = {An online robot self-calibration method based on an inertial measurement unit (IMU) and a position sensor is presented in this paper. In this method, a position marker and an IMU are required to be rigidly attached to the robot tool to obtain the position of the manipulator from the position sensor and the orientation of the manipulator from the IMU in real time. An efficient approach that incorporates a Kalman filter (KF) and a particle filter to estimate the position and orientation of the manipulator is proposed in this paper. The use of these pose (orientation and position) estimation methods improves the reliability and accuracy of pose measurements. Finally, an extended KF is used to estimate the kinematic parameter errors. The primary advantage of this method over existing automated self-calibration methods is that it does not involve complex steps, such as camera calibration, corner detection, and laser alignment, which makes the proposed robot calibration procedure more auton},
annote = {The paper uses EKF to handle kinematic errors in manipulators. The EKF allows auto-calibration without strenuos technique and expensive sensors. 

The IMU and the position sensors are attached at the end point of the serial robot. The implement their method using GOOGOL GRB3016 robot with six degree of freedom. 

Kinematic errors occur because of imperfection in serial robot components, their wear, misalignment and other factors. 

This paper also explained data fusion algorithm for their IMU attached at the end point of their serial robot:

-Particle filters is used to estimate the orientation of the end point of the serial robot

-Kalman filter is used to estimate the position of the end point of the serial robot

-The EKF is used to optimize the position and orientation estimation of the end point of the robot. By using the Jacobian matrices, the authors estimate the kinematic erros of the serial robot to manage the uncertainty of using IMU measurements.

They compared their EKF approach to a linear Least Square technique for their estimation of each joints in the robot. The EKF has llower error for all six joint parameters estimation.

This paper acclamates that their method of using IMU and position sensor (position marker) reduce the complex steps of auto-calibrating a manipulator, increase better accuracy, convenience, and effectiveness.



},
author = {Du, Guanglong and Zhang, Ping},
doi = {10.1109/TIE.2014.2314051},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Du, Zhang - 2014 - Online serial manipulator calibration based on multisensory process via extended kalman and particle filters.pdf:pdf},
isbn = {0278-0046},
issn = {02780046},
journal = {IEEE Transactions on Industrial Electronics},
keywords = {Extended Kalman filter (EKF),Kalman filter (KF),kinematic identification,online robot calibration,particle filter (PF)},
number = {12},
pages = {6852--6859},
title = {{Online serial manipulator calibration based on multisensory process via extended kalman and particle filters}},
volume = {61},
year = {2014}
}
@article{Sturm2011,
abstract = {Robots operating in domestic environments generally need to interact with articulated objects, such as doors, cabinets, dishwashers or fridges. In this work, we present a novel, probabilistic framework for modeling articulated objects as kinematic graphs. Vertices in this graph correspond to object parts, while edges between them model their kinematic relationship. In particular, we present a set of parametric and non-parametric edge models and how they can robustly be estimated from noisy pose observations. We furthermore describe how to estimate the kinematic structure and how to use the learned kinematic models for pose prediction and for robotic manipulation tasks. We finally present how the learned models can be generalized to new and previously unseen objects. In various experiments using real robots with different camera systems as well as in simulation, we show that our approach is valid, accurate and efficient. Further, we demonstrate that our approach has a broad set of applications, in particular for the emerging fields of mobile manipulation and service robotics.},
author = {Sturm, J{\"{u}}rgen and Stachniss, Cyrill and Burgard, Wolfram},
doi = {10.1613/jair.3229},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sturm, Stachniss, Burgard - 2011 - A probabilistic framework for learning kinematic models of articulated objects.pdf:pdf},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
pages = {477--526},
title = {{A probabilistic framework for learning kinematic models of articulated objects}},
volume = {41},
year = {2011}
}
@article{Potthast2011,
annote = {Use this paper together with 

"Autonomous robot manipulator-based exploration and mapping system for bridge maintenance" Paul et al. (2011)

on uncertainty in unknown environment and how to maximize information gain

This paper address a novel approach to the Next best veiw (NBV) problem: to find a location in space for a manipulator to achieve the highest information gain. The author uses Probabilistic Roadmap for their motion planning approach. The estimate a pose by predicting multiple position in the manipulator's workspace and calculate the information gain from each position; they call this stage as the virtual scanning. 

They use occupancy grid map as their initial estimation of the workspace model. This model is accounted because of noise of the Kinect sensor used in their work. However the paper are more interested in the uncertainty management of the unknown space where the point could from the Kinect are not detected at a certain region in the workspace.

They have only run simulation of their method based on PR2 robot platform.},
author = {Potthast, Christian and Sukhatme, Gaurav S},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Skoglund et al. - 2010 - First Steps Towards a Robotic System for Flexible Volumetric Mapping of Indoor Environments(6).pdf:pdf},
journal = {IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS)},
title = {{Next best view estimation with eye in hand camera}},
year = {2011}
}
@article{Triebel2004,
annote = {Use this paper as an example to mapping 3D using occupancy grid map to measure information gain based on entropy.},
author = {Triebel, Rudolph and Frank, Barbara and Meyer, Joerg and Burgard, Wolfram},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Skoglund et al. - 2010 - First Steps Towards a Robotic System for Flexible Volumetric Mapping of Indoor Environments(10).pdf:pdf},
journal = {5th IFAC/EURON Symposium on Intelligent Autonomous Vehicles},
keywords = {3d collision detection,3d mapping,exploration,obb-trees},
title = {{First Steps Towards a Robotic System for Flexible Volumetric Mapping of Indoor Environments}},
year = {2004}
}
@article{Mirzaei2008,
abstract = {Vision-aided inertial navigation systems (V-INSs) can provide precise state estimates for the 3-D motion of a vehicle when no external references (e.g., GPS) are available. This is achieved by combining inertial measurements from an inertial measurement unit (IMU) with visual observations from a camera under the assumption that the rigid transformation between the two sensors is known. Errors in the IMU-camera extrinsic calibration process cause biases that reduce the estimation accuracy and can even lead to divergence of any estimator processing the measurements from both sensors. In this paper, we present an extended Kalman filter for precisely determining the unknown transformation between a camera and an IMU. Contrary to previous approaches, we explicitly account for the time correlation of the IMU measurements and provide a figure of merit (covariance) for the estimated transformation. The proposed method does not require any special hardware (such as spin table or 3-D laser scanner) except a calibration target. Furthermore, we employ the observability rank criterion based on Lie derivatives and prove that the nonlinear system describing the IMU-camera calibration process is observable. Simulation and experimental results are presented that validate the proposed method and quantify its accuracy.},
annote = {KIV},
author = {Mirzaei, Faraz M. and Roumeliotis, Stergios I.},
doi = {10.1109/TRO.2008.2004486},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mirzaei, Roumeliotis - 2008 - A Kalman filter-based algorithm for IMU-camera calibration Observability analysis and performance evaluati.pdf:pdf},
isbn = {1424409128},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Extended Kalman filter,Inertial measurement unit (IMU)-camera calibration,Lie derivatives,Observability of nonlinear systems,Vision-aided inertial navigation},
number = {5},
pages = {1143--1156},
title = {{A Kalman filter-based algorithm for IMU-camera calibration: Observability analysis and performance evaluation}},
volume = {24},
year = {2008}
}
@article{Skoglund2006,
annote = {This paper proposal a theoretical framework for teach by demonstration where a robot is given a task to mimic a human wearing a motion capturing device.

The teaching by demonstration eliminate the need for a manipulator to perform motion planning task. The manipulator is trained using Q-learning approach so that the motion can be replicated. 

Their result has no benchmark but they report the success of the manipulator to replicate the motion of the demonstrator

Their approach however, uses occupancy grid map to represent the workspace of the robot. The occupancy grid map act as an uncertainty management part of their teaching by demonstration method to improve the movement of the robot when sonar sensors are used. A sonar sensor gives out noise ridden measurements. This improvement entails the understanding of free space and the feasibility to repeat a learn motion in an this free space that may change in the future under the use of noisy sensor measurement. By using occupancy grid map. To map the movement of the demonstrator into the robot configuration space, they use a pseudo inverted Jacobian matrix which reduce the higher degree of freedom of the demonstrator to an appropriate degree of freedom of the manipulator.},
author = {Skoglund, Alexander and Duckett, Tom and Iliev, Boyko and Lilienthal, Achim and Palm, Rainer},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Skoglund et al. - 2010 - First Steps Towards a Robotic System for Flexible Volumetric Mapping of Indoor Environments(11).pdf:pdf},
isbn = {0780395050},
number = {May},
pages = {4339--4341},
title = {{Teaching by Demonstration of Robotic Manipulators in Non-Stationary Environments}},
year = {2006}
}
@article{Jassemi-Zargani2002,
abstract = { Accurate measurements of positions, velocities, and accelerations in both joint and operational space are required for achieving accurate operational space motion control of robots. Servomotors used for joint actuation are normally equipped with position sensors and optionally with velocity sensors for interlink motion measurements. Further improvements in measurement accuracy can be obtained by equipping the robot arm with accelerometers for absolute acceleration measurement. In this paper, an extended Kalman filter is used for multisensor fusion. The real-time control algorithm was previously based on the assumption of a jerk represented as a processed white noise with the zero mean. In reality, the accelerations are varying in time during the arm motion, and the zero mean assumption is not valid, particularly during fast accelerating periods. In this paper, a model predictive control approach is used for predetermining next-time-step jerk such that the remaining term can be modeled as Gaussian white noise. Experimental results illustrate the effectiveness of the proposed sensor fusion approach.},
annote = {use this as an introduction to data fusion estimation. Do not elaborate

They use extended Kalman filter to fuse data from high resolution joint resolver. A joint resolver is a control unit that performs calculation of the inverse transformation of a manipulator from data obtained from the end effector. The authors use the data from two accelerometer to estimate the position of each joints in their manipulator and use these measurements in their extended kalman filter observer to estimate the acceleration (or the jerking) of the end effector.},
author = {Jassemi-Zargani, R. and Necsulescu, D.},
doi = {10.1109/TIM.2002.808050},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jassemi-Zargani, Necsulescu - 2002 - Extended kalman filter-based sensor fusion for operational space control of a robot arm.pdf:pdf},
issn = {0018-9456},
journal = {IEEE Transactions on Instrumentation and Measurement},
number = {6},
pages = {1279--1282},
title = {{Extended kalman filter-based sensor fusion for operational space control of a robot arm}},
url = {http://ieeexplore.ieee.org/document/1177924/},
volume = {51},
year = {2002}
}
@article{Janabi-Sharifi2010,
abstract = {The problem of estimating position and orientation (pose) of an object in real time constitutes an important issue for vision-based control of robots. Many vision-based pose-estimation schemes in robot control rely on an extended Kalman filter (EKF) that requires tuning of filter parameters. To obtain satisfactory results, EKF-based techniques rely on “known” noise statistics, initial object pose, and sufficiently high sampling rates for good approximation of measurement-function linearization. Deviations from such assumptions usually lead to degraded pose estimation during visual servoing. In this paper, a new algorithm, namely iterative adaptive EKF (IAEKF), is proposed by integrating mechanisms for noise adaptation and iterative-measurement linearization. The experimental results are provided to demonstrate the superiority of IAEKF in dealing with erroneous a priori statistics, poor pose initialization, variations in the sampling rate, and trajectory dynamics.},
annote = {During visual servoing of a manipulator, the pose of the end effector is determined from an intial estimate of its position. This paper demonstrate an adaptive iterative extended Kalman filter (AIEKF) in the absence of accurate inital pose, noise matrix, and covariance matrix at variant sampling rate during robotic visual servoing. Visual servoing is a process of estimating the configuration of a manipulator using images or visual feedbacks.

They experimented on a six degree of freedom cartesian manipulator AFMA-6 with eye-in-hand camera configuration. The robot moves at a predefined trajectory under different condition. Each separate experimentation involves increasing the velocity of the end effector, changing the covariance matrices, changing the sampling time for estimation, and changing the intial positions of the end effector. They compared three other Kalman filtering techniques (extended Kalman filter, adaptive extended Kalman filter, and iterative extended Kalman filter) with the IAEKF. They conclude that IAEKF can improve pose estimation at during uncertain initial position and covariance matrix estimation, high motion, and slow sampling rate},
author = {Janabi-Sharifi, Farrokh and Marey, Mohammed},
doi = {10.1109/TRO.2010.2061290},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Janabi-Sharifi, Marey - 2010 - A Kalman-filter-based method for pose estimation in visual servoing.pdf:pdf},
isbn = {0471391263},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Adaptation,Kalman filter (KF),control,pose estimation,robotic manipulator,visual servoing},
number = {5},
pages = {939--947},
title = {{A Kalman-filter-based method for pose estimation in visual servoing}},
volume = {26},
year = {2010}
}
@inproceedings{Haghighipanah2016,
abstract = {Cable driven manipulators are popular in surgical robots due to compact design, low inertia, and remote actuation. In these manipulators, encoders are usually mounted on the motor, and joint angles are estimated based on transmission kinematics. However, due to non-linear properties of cables such as cable stretch, lower stiffness, and uncertainties in kinematic model parameters, the precision of joint angle estimation is limited with transmission kinematics approach. To improve the positioning of these manipulators, we use a pair of low cost stereo camera as the observation for joint angles and we input these noisy measurements into an Unscented Kalman Filter (UKF) for state estimation. We use the dual UKF to estimate cable parameters and states offline. We evaluated the effectiveness of the proposed method on a Raven-II experimental surgical research platform. Additional encoders at the joint output were employed as a reference system. From the experiments, the UKF improved the accuracy of joint angle estimation by 33- 72{\%}. Also, we tested the reliability of state estimation under camera occlusion. We found that when the system dynamics is tuned with offline UKF parameter estimation, the camera occlusion has no effect on the online state estimation. {\&}copy; 2016 IEEE.},
annote = {This paper improved the technique of estimation done by the same group of researcher (Haghiglipanah et al.; 2015) by using stereo vision instead of an encoder attached to the motor. 

THey also model the flexible cable to be both rigid and flexible. 
They imporve the accuracy of the joint position to 43.14{\%}, 33.42{\%}, 72.05{\%} for joints 1, 2, 3 respectively.},
author = {Haghighipanah, Mohammad and Miyasaka, Muneaki and Li, Yangming and Hannaford, Blake},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2016.7487606},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haghighipanah et al. - 2016 - Unscented Kalman Filter and 3D vision to improve cable driven surgical robot joint angle estimation.pdf:pdf},
isbn = {9781467380263},
issn = {10504729},
keywords = {Unscented Kalman Filter,cable driven mechanism,flexible manipulators,surgical robots},
pages = {4135--4142},
title = {{Unscented Kalman Filter and 3D vision to improve cable driven surgical robot joint angle estimation}},
volume = {2016-June},
year = {2016}
}
@article{Payeur2002,
annote = {Please do not use this in review: reiterating Elves and Moravec approach and basically describing SLAM

This paper present the importance of understanding the propogating errors in robotic system from uncertainty in visual based measurement, uncertainty in localization or state estimation, and so forth. The author propose merging the uncertainty into an occupancy grid that models an environment.},
author = {Payeur, P.},
doi = {10.1109/VIMS.2002.1009357},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Payeur - 2002 - Dealing with uncertain measurements in virtual representations for robot guidance.pdf:pdf},
isbn = {0780373448},
journal = {VIMS 2002 - 2002 IEEE International Symposium on Virtual and Intelligent Measurement Systems: Distributed Intelligent Sensing for Advanced Integrated Virtual Environments},
number = {May},
pages = {56--61},
title = {{Dealing with uncertain measurements in virtual representations for robot guidance}},
year = {2002}
}
@article{Kruse1996,
annote = {The paper present a method for exploring an unknown environment using either a mobie robot or a manipulator robot. Their method uses a planning-sensing-updating cycle. This research uses an occupancy grid map to represent the unknown environment.

"Sampling based motion planning with sensing uncertainty" by Burns and Brock (2007) is based on?

Their rating approach is similar too Burns and Brocks utility and cost concept. However they relate their rating function with the manipulator's configuration space by introducing constraint for fast exploration .

PLEASE USE THIS AS A SUPPORTING ARGUMENT' FOR BROCK AND BURNS; 2007},
author = {Kruse, E and Gutsche, R and Wahl, FM},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kruse, Gutsche, Wahl - 1996 - Efficient, iterative, sensor based 3-D map building using rating functions in configuration space.pdf:pdf},
journal = {Robotics and Automation, 1996. {\ldots}},
number = {April},
pages = {1067--1072},
title = {{Efficient, iterative, sensor based 3-D map building using rating functions in configuration space}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=506850},
year = {1996}
}
@article{Klingensmith2016,
abstract = {A robot with a hand-mounted depth sensor scans a scene. When the robot's joint angles are not known with certainty, how can it best reconstruct the scene? In this work, we simultaneously estimate the joint angles of the robot and reconstruct a dense volumetric model of the scene. In this way, we perform simultaneous localization and mapping in the configuration space of the robot, rather than in the pose space of the camera. We show using simulations and robot experiments that our approach greatly reduces both 3D reconstruction error and joint angle error over simply using the forward kinematics. Unlike other approaches, ours directly reasons about robot joint angles, and can use these to constrain the pose of the sensor. Because of this, it is more robust to missing or ambiguous depth data than approaches that are unconstrained by the robot's kinematics.},
annote = {The paper present a Simultaneous localization and mapping using a manipulator. Simultaneous localization and mapping involves obtaining a solution for pose estimation through map learning and vice versa simultaneously. 



The authors argue that encoders on each joints of a manipulator is not enough to estimate the end point of a manipulator due to gear trash, cable strechm non-rigid deformation and others.

The ARM-SLAM uses TSDF as part of the scene reconstruction to help estimate the pose of the end effector. TSDF is a variant of Dense Fusion 

They ARM-SLAM assume eye-in-hand configuration.

They conducted three experiments to validate their SLAM solution:
-2D simulation where they compare pose error between forward kinematics, Dense Fusion algorithm and ARM-SLAM algorithm. The result shows significant error reduction for both of the two algorithms compared to the forward kinematics calculation. ARM-SLAM, however, has the lowest errors.

-in their 3D simulation experiment, the authors compare results for forward kinematics calculation with kinect fusion and ARM-SLAM. They observed that ARM-SLAM is more robust when lost of data occurs.

-real shelf scanning experiments. In this experiment, the authors could not conclusively see better pose estimation with compared to the forward kinematics calculation. However, they reiterate that during lost of data, the ARM-SLAM solution produce robust estimation.

However, the paper does not deal with path planning},
author = {Klingensmith, Matthew and Sirinivasa, Siddartha S. and Kaess, Michael},
doi = {10.1109/LRA.2016.2518242},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klingensmith, Sirinivasa, Kaess - 2016 - Articulated Robot Motion for Simultaneous Localization and Mapping (ARM-SLAM).pdf:pdf},
isbn = {9781467380256},
issn = {23773766},
journal = {IEEE Robotics and Automation Letters},
keywords = {Kinematics,Mapping,RGBD Perception,SLAM,Visual-Based navigation},
number = {2},
pages = {1156--1163},
title = {{Articulated Robot Motion for Simultaneous Localization and Mapping (ARM-SLAM)}},
volume = {1},
year = {2016}
}
@article{Leven2002,
annote = {KIV},
author = {Leven, Peter and Hutchinson, Seth},
doi = {10.1177/0278364902021012001},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leven, Hutchinson - 2002 - A Framework for Real-time Path Planning in Changing Environments.pdf:pdf},
issn = {0278-3649},
journal = {Int. J. Robot. Res.},
keywords = {motion planning,probabilistic roadmaps},
number = {12},
pages = {999--1030},
title = {{A Framework for Real-time Path Planning in Changing Environments}},
url = {http://ijr.sagepub.com/cgi/doi/10.1177/0278364902021012001},
volume = {21},
year = {2002}
}
@article{Corrales2008,
abstract = {The precise localization of human operators in robotic workplaces is an important requirement to be satisfied in order to develop human-robot interaction tasks. Human tracking provides not only safety for human operators, but also context information for intelligent human-robot collaboration. This paper evaluates an inertial motion capture system which registers full-body movements of an user in a robotic manipulator workplace. However, the presence of errors in the global translational measurements returned by this system has led to the need of using another localization system, based on Ultra-WideBand (UWB) technology. A Kalman filter fusion algorithm which combines the measurements of these systems is developed. This algorithm unifies the advantages of both technologies: high data rates from the motion capture system and global translational precision from the UWB localization system. The developed hybrid system not only tracks the movements of all limbs of the user as previous motion capture systems, but is also able to position precisely the user in the environment.},
annote = {USE IN DATA FUSION INTRODUCTION with APPROPRIATE DIAGRAM (PLEASE REFER TO PHYSICAL NOTE)

This paper uses kalman filter fusion algorithm to fuse ultra-wideband (UWB) technology and inertial motion capture system to estimate the motion of human operator in industrial environment. 

The algorithm improves the interaction between a robot and a human operator/user by localizing a human in a manipulator's workspace so that a cooperative interaction can be made. Since the authors use UWB sensor to estimate the location of the human, they use Kalman filtering technique to fuse the information coming from the UWB and the inertial sensors. The filtering technique compensate the low data rate of the UWB and the high error from inertial sensor. Their Kalman filter uses the global position of the UWB as the correction step and the inertial sensor as the prediction step.

Their result shows that by fusing two measurements using kalman filter algorithm, the state estimation of the person's location is increased in accuracy.},
author = {Corrales, J. a. and Candelas, F. a. and Torres, F.},
doi = {10.1145/1349822.1349848},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Corrales, Candelas, Torres - 2008 - Hybrid tracking of human operators using IMUUWB data fusion by a Kalman filter.pdf:pdf},
isbn = {9781605580173},
issn = {2167-2121},
journal = {Proceedings of the 3rd international conference on Human robot interaction - HRI '08},
keywords = {Kalman filter,Motion capture,UWB,data fusion,human tracking and monitoring,indoor location,inertial sensors},
pages = {193 -- 200},
title = {{Hybrid tracking of human operators using IMU/UWB data fusion by a Kalman filter}},
url = {http://portal.acm.org/citation.cfm?doid=1349822.1349848},
year = {2008}
}
@article{Koval2013,
abstract = {We investigate the problem of using contact sensors to estimate the pose of an object during planar pushing by a fixed-shape hand. Contact sensors are unique because they inherently discriminate between "contact" and "no-contact" configurations. As a result, the set of object configurations that activates a sensor constitutes a lower-dimensional contact manifold in the configuration space of the object. This causes conventional state estimation methods, such as the particle filter, to perform poorly during periods of contact due to particle starvation. In this paper, we introduce the manifold particle filter as a principled way of solving the state estimation problem when the state moves between multiple manifolds of different dimensionality. The manifold particle filter avoids particle starvation during contact by adaptively sampling particles that reside on the contact manifold from the dual proposal distribution. We describe three techniques, one analytical and two sample-based, of sampling from the dual proposal distribution and compare their relative strengths and weaknesses. We present simulation results that show that all three techniques outperform the conventional particle filter in both speed and accuracy. In addition, we implement the manifold particle filter on a real robot and show that it successfully tracks the pose of a pushed object using commercially available tactile sensors.},
annote = {The author present a situation where constant contact and manipulation of an object, by pushing the object, can be used to estimate the state of the object; i. e. the position and the orientation of the object. They term the process as contact manipulation. 

They argue that with the absence of more conventional observation from sensors such as a laser range finder and a vision camera, tactile based sensor can perform state estimation using appropriate filtering technique. Since tactile sensor has non-gaussian characteristic and highly nonlinear, the authors used particle filter as their estimator. 

The use of tactile sensor, however, introduce uncertainty because the sensor has low spatial resolution or low manifold. This is regarded as a low-dimensional manifold problem where the state estimation has higher dimensionality (two for position on a plane and one for orientation). Although intuitively increasing the resolution of the tactile sensor may decrease the spatial uncertainty, it is not the case for tactile sensing with particle filtering technique. Thus, the authors introduce manifold particle filter. (MPF).

An MPF reduce the dimensionality of the state estimation by marginalizing the probability distribution of the state of the object based on the observation from the tactile sensing and use it as a prior estimate.

To implement the MPF, the state estimation follows three steps:
(a) assumption of the state of the object by evenly weighting particles
(b) action which involve pushing the object
(c) observation where the MPF use the pressure profile during pushing to estimate the state of the object.

They implement the algorithm using OpenRAVE simulation environment and evaluate it with a simulated BarrettHand. They then run an experiment using Andy, a robot module developed for Darpa ARM-S competition. They compared their result with a conventional particle filter (CPF) and imporved estimation of the object state.},
author = {Koval, Michael C. and Dogar, Mehmet R. and Pollard, Nancy S. and Srinivasa, Siddhartha S.},
doi = {10.1109/IROS.2013.6697009},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koval et al. - 2013 - Pose estimation for contact manipulation with manifold particle filters.pdf:pdf},
isbn = {9781467363587},
issn = {21530858},
journal = {IEEE International Conference on Intelligent Robots and Systems},
pages = {4541--4548},
title = {{Pose estimation for contact manipulation with manifold particle filters}},
url = {https://www.ri.cmu.edu/pub{\_}files/2013/5/paper.pdf},
year = {2013}
}
@article{Elahinia2004,
annote = {DO NOT USE IN THE REVIEW},
author = {Elahinia, Mohammad H and Ahmadian, Mehdi and Ashrafiuon, Hashem},
doi = {10.1088/0964-1726/13/4/006},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elahinia, Ahmadian, Ashrafiuon - 2004 - Design of a Kalman filter for rotary shape memory alloy actuators.pdf:pdf},
issn = {0964-1726},
journal = {Smart Materials and Structures},
number = {4},
pages = {691--697},
title = {{Design of a Kalman filter for rotary shape memory alloy actuators}},
url = {http://stacks.iop.org/0964-1726/13/i=4/a=006?key=crossref.ab589994a24d9dc1c133dd869d38a905},
volume = {13},
year = {2004}
}
@article{Stilman2005,
abstract = {The successful development of autonomous robotic systems requires careful fusion of complex subsystems for perception, planning, and control. Often these subsystems are designed in a modular fashion and tested individually. However, when ultimately combined with other components to form a complete system, unexpected interactions between subsystems can occur that make it difficult to isolate the source of problems. This paper presents a novel paradigm for robot experimentation that enables unified testing of individual subsystems while acting as part of a complete whole made up of both virtual and real components. We exploit the recent advances in speed and accuracy of optical motion capture to localize the robot, track environment objects, and extract extrinsic parameters for moving cameras in real-time. We construct a world model representation that serves as ground truth for both visual and tactile sensors in the environment. From this data, we build spatial and temporal correspondences between virtual elements, such as motion plans, and real artifacts in the scene. The system enables safe, decoupled testing of component algorithms for vision, motion planning and control that would normally have to be tested simultaneously on actual hardware. We show results of successful online applications in the development of an autonomous humanoid robot.},
annote = {Not relevant to industrial manipulator

DONT USE FOR REVIEW},
author = {Stilman, Mike and Michel, Philipp and Chestnutt, Joel},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stilman, Michel, Chestnutt - 2005 - Augmented reality for robot development and experimentation.pdf:pdf},
isbn = {CMU-RI-TR-05-55},
journal = {{\ldots} . Rep. CMU-RI-TR-05-55},
pages = {1--11},
title = {{Augmented reality for robot development and experimentation}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.71.9737{\&}rep=rep1{\&}type=pdf},
year = {2005}
}
@article{Zacharias2007,
abstract = {Humans have at some point learned an abstraction of the capabilities of their arms. By just looking at the scene they can decide which places or objects they can easily reach and which are difficult to approach. Possessing a similar abstraction of a robot arm's capabilities in its workspace is important for grasp planners, path planners and task planners. In this paper, we show that robot arm capabilities manifest themselves as directional structures specific to workspace regions. We introduce a representation scheme that enables to visualize and inspect the directional structures. The directional structures are then captured in the form of a map, which we name the capability map. Using this capability map, a manipulator is able to deduce places that are easy to reach. Furthermore, a manipulator can either transport an object to a place where versatile manipulation is possible or a mobile manipulator or humanoid torso can position itself to enable optimal manipulation of an object.},
author = {Zacharias, Franziska and Borst, Christoph and Hirzinger, Gerd},
doi = {10.1109/IROS.2007.4399105},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zacharias, Borst, Hirzinger - 2007 - Capturing robot workspace structure Representing robot capabilities.pdf:pdf},
isbn = {1424409128},
journal = {IEEE International Conference on Intelligent Robots and Systems},
pages = {3229--3236},
title = {{Capturing robot workspace structure: Representing robot capabilities}},
year = {2007}
}
@article{Ruhr2012,
abstract = {In this paper, we present a generalized framework for robustly operating previously unknown cabinets in kitchen environments. Our framework consists of the following four components: (1) a module for detecting both Lambertian and non-Lambertian (i.e. specular) handles, (2) a module for opening and closing novel cabinets using impedance control and for learning their kinematic models, (3) a module for storing and retrieving information about these objects in the map, and (4) a module for reliably operating cabinets of which the kinematic model is known. The presented work is the result of a collaboration of three PR2 beta sites. We rigorously evaluated our approach on 29 cabinets in five real kitchens located at our institutions. These kitchens contained 13 drawers, 12 doors, 2 refrigerators and 2 dishwashers. We evaluated the overall performance of detecting the handle of a novel cabinet, operating it and storing its model in a semantic map. We found that our approach was successful in 51.9{\%} of all 104 trials. With this work, we contribute a well-tested building block of open-source software for future robotic service applications.},
annote = {Uncertainty management by learning

This paper present solution to manipulation task which involve opening and closing doors and drawers in any kitchen environment. Their approach involve the management of uncertainty of door handling through learning. Within their learning model framework, the authors use 3D point clouds directly to identify door or cabinet handles. They use RANSAC with the point clouds to segments the point clouds to help detect the handles based on identification of planes that parameterized a wall, ceilingm floor, and cabinets. They also implement real-time impedence control and kinematic model learning to estimate the kinematics of animated objects in the kitchen. They also use a higher level of abstraction in representing the environment via semantic maps.

They evaluated their approach using PR2 mobile aritucalated robot which has 7DOF manipulator. They report out of 104 trials of opening and closing cabinets and doors, the rate of success is 51.9{\%}.},
author = {Ruhr, Thomas and Sturm, Jurgen and Pangercic, Dejan and Beetz, Michael and Cremers, Daniel},
doi = {10.1109/ICRA.2012.6224929},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ruhr et al. - 2012 - A generalized framework for opening doors and drawers in kitchen environments.pdf:pdf},
isbn = {9781467314039},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
pages = {3852--3858},
title = {{A generalized framework for opening doors and drawers in kitchen environments}},
year = {2012}
}
@article{Westmore1991,
abstract = {The development of a control strategy for direct dynamic end-point$\backslash$ncontrol of a manipulator based on position estimates obtained from$\backslash$nendpoint mounted sensors is presented. The feasibility of using an$\backslash$nextended Kalman filter algorithm for relative position estimates based$\backslash$non task object feature locations extracted from images obtained from an$\backslash$nend-point mounted camera has been studied. An experimental system has$\backslash$nbeen constructed and the position estimation and control strategy$\backslash$nimplemented to test the performance of the design. Tests have$\backslash$ndemonstrated the successful operation of the control strategy developed$\backslash$nand have also demonstrated the feasibility of using an extended Kalman$\backslash$nfilter for relative position estimates at a sample rate of 61 Hz},
annote = {This paper uses Kalman filtering technique to help track an object on a flat surface. The use of extended Kalman filter aside from the trajectory control of the end point of the robot increase certainty of the pose estimation and the accuracy of the tracking.

A camera is mounted on the end point of CRS Plus SRS-M1A robot system. The robot is presented with a task to follow the object using the eye-in-hand camera. The visual feedback from the camera is use with their control strategy. The extended Kalman filter is use to predict the relative position of the object while it is moving.

Since the researcher maintain a constant velocity to the object, the tracking can use a Kalman filtering technique without linearization. However, since the tracking of the object requires the movement of the camera, given the nonlinearity of an inverse kinematic solution of their robot system, the use of extended Kalman filter is justified. The filter maintain the estimation of the end effector's pose. Although the robot manage to follow the moving object in their experimentation, the authors did not compare and reiterate their experimentation with other estimation method.},
author = {Westmore, D.B. and Wilson, W.J.},
doi = {10.1109/ROBOT.1991.131759},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Westmore, Wilson - 1991 - Direct dynamic control of a robot using an end-point mounted camera and Kalman filter position estimation.pdf:pdf},
isbn = {0-8186-2163-X},
issn = {10504729},
journal = {Proceedings. 1991 IEEE International Conference on Robotics and Automation},
number = {April},
pages = {2376--2384},
title = {{Direct dynamic control of a robot using an end-point mounted camera and Kalman filter position estimation}},
year = {1991}
}
@article{Kumar2004,
annote = {Uncertainty management using data fusion to model the environment.

This paper fuse measurements from a proximity sensor attached to the end point of the manipulator and a visual sensor (a camera) attached on top of a workcell to model the workspace. They also use kalman filtering technique to estimate the force acting on the end effector. 
This paper shows a good example of the model of an unknown world using probabilistic approach which is the fusion of two sensor using bayesian filtering technique to estimate the occupancy of a space in the workspace of a robot.

They argue that after experimentation, occupancy grid cell map performance is dependent on the size of the cell.},
author = {Kumar, Manish and Garg, Devendra P and Fellow, Asme L},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar, Garg, Fellow - 2004 - Intelligent Multi-Sensor Fusion Techniques in Flexible Manufacturing Workcells.pdf:pdf},
isbn = {0780383354104},
pages = {5375--5380},
title = {{Intelligent Multi-Sensor Fusion Techniques in Flexible Manufacturing Workcells}},
year = {2004}
}
@article{Nissler2016,
abstract = {Given the advancing importance for light-weight production materials an increase in automation is crucial. This paper presents a prototypical setup to obtain a precise pose estimation for an industrial manipulator in a realistic production environment. We show the achievable precision using only a standard fiducial marker system (AprilTag) and a state-of-the art camera attached to the robot. The results obtained in a typical working space of a robot cell of about 4.5m {\&}times; 4.5m are in the range of 15mm to 35mm compared to ground truth provided by a laser tracker. We then show several methods of reducing this error by applying state-of-the-art optimization techniques, which reduce the error significantly to less than 10mm compared to the laser tracker ground truth data and at the same time remove e{\&}times;isting outliers.},
annote = {The purpose of this paper is to demonstrate the use of fully autonomous handling of CFRP material.

The paper is similar to SLAM solution method where AprilTag is used as a feature observed by the measurement to optimize the pose estimation of the end effector and at the same time using the pose estimation to track the AprilTag on a work space. The author RANSAC solution to fuse multiple scene from sensors, an eye-in-hand camera, that may contain outliers.

The authors use KUKA KR 210 with a AVT GigE camera attached to the end point. The robot follows three different motion; a horizontal arc, a verticle arc, and a approach motion. A laser tracker is used to calibrate the position of the robot and the markers. A single AprilTag marker was tracked during the motion. The motions were repeated while tracking multiple AprilTag markers. RANSAC method was compared with a least square method.

They observed that RANSAC method that they developed for the AprilTag tracking improves the estimation of the end effectors pose.},
author = {Nissler, Christian and Buttner, Stefan and Marton, Zoltan Csaba and Beckmann, Laura and Thomasy, Ulrike},
doi = {10.1109/ETFA.2016.7733711},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nissler et al. - 2016 - Evaluation and improvement of global pose estimation with multiple AprilTags for industrial manipulators.pdf:pdf},
isbn = {9781509013142},
issn = {19460759},
journal = {IEEE International Conference on Emerging Technologies and Factory Automation, ETFA},
title = {{Evaluation and improvement of global pose estimation with multiple AprilTags for industrial manipulators}},
volume = {2016-Novem},
year = {2016}
}
@article{Leu1990,
author = {Leu, Ming C},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leu - 1990 - Planning Optimal Robot Trajectories by Cell Mapping Wen.pdf:pdf},
isbn = {0818620617},
pages = {1730--1735},
title = {{Planning Optimal Robot Trajectories by Cell Mapping Wen}},
volume = {4},
year = {1990}
}
@article{Badamchizadeh2010,
abstract = {Robust nonlinear control of flexible-joint robots requires that the link position, velocity, acceleration, and jerk be available. In this paper, we derive the dynamic model of a nonlinear flexible-joint robot based on the governing Euler-Lagrange equations and propose extended and unscented Kalman filters to estimate the link acceleration and jerk from position and velocity measurements. Both observers are designed for the same model and run with the same covariance matrices under the same initial conditions. A five-bar linkage robot with revolute flexible joints is considered as a case study. Simulation results verify the effectiveness of the proposed filters. Copyright {\textcopyright} 2010 Mohammad Ali Badamchizadeh et al.},
annote = {The authors present the design of two filtering techniques to estimate the acceleration and the jerk of five-bar linkage manipulator with flexible joints. These estimations helps in designing a better control.

Unlike a rigid joints, the flexible joints are time variant hence highly nonlinear. The nonlinearity introduce uncertainty to the dynamics of the manipulator making prediction of higher order dynamics such as accelerations and jerks uncertain. This is because a nonlinear system has no closed form solution and require linearization. The authors suggest the use of Euler-Langrange equations to represent the model of the manipulator dynamics given that each joints are model by torsional spring. 

To better estimate the acceleration and jerk of each link in the four-bar linkage, the linearization are manage using extended and unscented Kalman filters. 

The author validated their observer model by simulation and conclude that the accelaration and jerk of the manipulator's linkages are succesfully estimated.},
author = {Badamchizadeh, Mohammad Ali and Hassanzadeh, Iraj and {Abedinpour Fallah}, Mehdi},
doi = {10.1155/2010/482972},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Badamchizadeh, Hassanzadeh, Abedinpour Fallah - 2010 - Extended and unscented kalman filtering applied to a flexible-joint robot with je.pdf:pdf},
issn = {10260226},
journal = {Discrete Dynamics in Nature and Society},
title = {{Extended and unscented kalman filtering applied to a flexible-joint robot with jerk estimation}},
volume = {2010},
year = {2010}
}
@article{Zhang2015,
abstract = {Purpose This paper aims to develop a wearable-based human-manipulator interface which integrates the interval Kalman filter (IKF), unscented Kalman filter (UKF), over damping method (ODM) and adaptive multispace transformation (AMT) to perform immersive human-manipulator interaction by interacting the natural and continuous motion of the human operators hand with the robot manipulator. Design/methodology/approach The interface requires that a wearable watch is tightly worn on the operators hand to track the continuous movements of the operators hand. Nevertheless, the measurement errors generated by the sensor error and tracking failure signicantly occur several times, which means that the measurement is not determined with sufficient accuracy. Due to this fact, IKF and UKF are used to compensate for the noisy and incomplete measurements, and ODM is established to eliminate the influence of the error signals like data jitter. Furthermore, to be subject to the inherent perceptive limitations of the human operator and the motor, AMT that focuses on a secondary treatment is also introduced. Findings Experimental studies on the GOOGOL GRB3016 robot show that such a wearable-based interface that incorporates the feedback mechanism and hybrid filters can operate the robot manipulator more flexibly and advantageously even if the operator is nonprofessional; the feedback mechanism introduced here can successfully assist in improving the performance of the interface. Originality/value The interface uses one wearable watch to simultaneously track the orientation and position of the operators hand; it is not only avoids problems of occlusion, identification and limited operating space, but also realizes a kind of two-way human-manipulator interaction, a feedback mechanism can be triggered in the watch to reflect the system states in real time. Furthermore, the interface gets rid of the synchronization question in posture estimation, as hybrid filters work independently to compensate the noisy measurements respectively. {\textcopyright} Emerald Group Publishing Limited [ISSN 0143-991X].},
annote = {KIV},
author = {Zhang, Ping and Li, Bei and Du, Guanglong},
doi = {10.1108/IR-04-2015-0065},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Li, Du - 2015 - Hybrid filters and feedback mechanism for wearable-based human-manipulator interface.pdf:pdf},
isbn = {0143991X (ISSN)},
issn = {0143-991X},
journal = {Industrial Robot: An International Journal},
keywords = {adaptive multispace transformation,human-manipulator interface,interval adaptive kalman filter,over damping method,paper type research paper,robotics,sensors,teleoperation,unscented kalman filter,wearable watch},
number = {5},
pages = {485--495},
title = {{Hybrid filters and feedback mechanism for wearable-based human-manipulator interface}},
url = {http://www.emeraldinsight.com/doi/10.1108/IR-04-2015-0065},
volume = {42},
year = {2015}
}
@inproceedings{Haghighipanah2015,
abstract = {Cable driven power transmission is popular in many manipulator applications including medical arms. In spite of advantages obtained by removing motors from the mechanism, cable transmission introduces higher non-linearity and more uncertainties such as cable stretch and cable coupling. In order to improve the control precision and robustness of the Raven-II surgical robot, particularly for automation applications, the Unscented Kalman Filter (UKF) was adopted for state estimation. The UKF estimated state variables of the Raven-II dynamic model from sensor data. The dual UKF was used offline to estimate cable coupling parameters. The experimental results showed that the proposed method improved joint position estimation precision and the estimation consistency, especially on the more elastic links. The improvements for links 2 and 3 of the Raven were 36.76{\%}, and 62.99{\%}, respectively. For link 1 the improvement was 1.43{\%} because the transmission is very stiff.},
annote = {This paper address nonlinearity problem of an elastic cable as power transmission between a motor and a joint for a surgical arm. The coupling between the motor and the robot joint reduce armature mass, inertia and size for expert surgery. However, the cable elasticity introduces uncertainty and nonlinearity to the kinematics and the dynamics of the surgical arm. 

The authors introduce an estimation method that uses a standard unscented Kalman filter (UKF) and a square root Kalman filter (srUKF) to estimate cable coupling parameter and the position of the end effector (end point) in real-time.

The authors implement their method using the Raven-II, a seven degree of freedom serial manipulator, as their surgical arm. The surgical arm is equip with an optical encoder attached to the motors and position sensor on each joint for data validation. In their research, the authors only address the first three joint for state estimation of the Raven-II.

They model the armature dynamics using forward and inverse dynamis with Newton-Euler equations . Their inverse dynamic solution is based on the recursive Newton-Euler algorithm.

The Newton-Euler equations requires model parameters. The authors identify the initial inertial matrices, mass and the center of mass of the system using a computer aided design model. 
The authors use srUKF to estimate the joint angle and joint position of the surgical arm online. Also, the authors use the standard UKF to estimate the coupling parameter offline. They compute spring constant, damping constant, coulomb and viscous friction of the motor side and the joint side experimentally (empirically) translate into a table?

They validate their method experimentally using three different design. The first two experiments involve changing the cable tension and the third experiment involve picking an object of the mass 100 g under high cable tension. They compared the reuslt of the three experiment between the dynamic model that uses their UKF estimation and the dynamic model that has no filtering technique. They improved the accuracy of the joints position to 1.433{\%}, 36.76{\%}, and 62.99{\%} for joints 1, 2 and 3 respectively},
author = {Haghighipanah, Mohammad and Li, Yangming and Miyasaka, Muneaki and Hannaford, Blake},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2015.7353646},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haghighipanah et al. - 2015 - Improving position precision of a servo-controlled elastic cable driven surgical robot using Unscented Kal.pdf:pdf},
isbn = {9781479999941},
issn = {21530866},
keywords = {Unscented Kalman Filter,cable driven mechanism,flexible manipulators,surgical robots},
pages = {2030--2036},
title = {{Improving position precision of a servo-controlled elastic cable driven surgical robot using Unscented Kalman Filter}},
volume = {2015-Decem},
year = {2015}
}
@inproceedings{Hebert2012,
abstract = {This paper develops an estimation framework for sensor-guided$\backslash$nmanipulation of a rigid object via a robot arm. Using an unscented$\backslash$nKalman Filter (UKF), the method combines dense range information (from$\backslash$nstereo cameras and 3D ranging sensors) as well as visual appearance$\backslash$nfeatures and silhouettes of the object and manipulator to track both an$\backslash$nobject-fixed frame location as well as a manipulator tool or palm frame$\backslash$nlocation. If available, tactile data is also incorporated. By using$\backslash$nthese different imaging sensors and different imaging properties, we can$\backslash$nleverage the advantages of each sensor and each feature type to realize$\backslash$nmore accurate and robust object and reference frame tracking. The method$\backslash$nis demonstrated using the DARPA ARM-S system, consisting of a Barrett TM$\backslash$nWAM manipulator.},
annote = {The paper present data fusion algorithm using unscented kalman filter to estimate the manipulator tool and teh manipulated object simultaneously.

The fusion algorihtm is used to manage the uncertainty of the end effector location as a result of uncertain actuation because of unknown weight of the manipulated object. Also, the authors uses Barret WAM manipulator that introduce further uncertainty in actuation as a result of tendon actuatation similar to flexible cable actuation. These uncertainty prompts the use of two type of sensors as a visual feedback together with a tactile sensing

They use unscented Kalman filter to fuse image features that covers dense range, visual appearance, silhouette of manipulator arm, multi-figered hand and grasped object. To fuse these measurement, the authoers model three measurements. 
(1) measurement model for ahdn tracking by using apprearance, shape and silhouette
(2) object tracking measureent using point cloud association similar to iteratice closest points
(3) tactile measurement model to represent a binary state of contact between the fingers of the manipulator and the manipulated object

They use DARPA ARM-S with Barret WAM manipulator to validate their methods experimentally

The experiment involves the tasks of grasping a hand-driller and drilling a red hole on a wooden block with the grasped drill.

The authors report an average of 9.3 mm drilling deviation when the sensor measurements are incorporated into the tasks and an average of 47.5 mm drilling deviation without the aide of any sensor},
author = {Hebert, Paul and Hudson, Nicolas and Ma, Jeremy and Howard, Thomas and Fuchs, Thomas and Bajracharya, Max and Burdick, Joel},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2012.6225084},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hebert et al. - 2012 - Combined shape, appearance and silhouette for simultaneous manipulator and object tracking.pdf:pdf},
isbn = {9781467314039},
issn = {10504729},
pages = {2405--2412},
title = {{Combined shape, appearance and silhouette for simultaneous manipulator and object tracking}},
year = {2012}
}
@article{Wongwilai2014,
abstract = {A typical grasping system consists of three subtasks: object model acquisition, grasping point calculation and navigation of the robotic arm. These tasks are usually considered separately. In this paper, we present a framework that combines these steps together. Our main motivation is that as the robot are moving, new information should be obtained from the sensor and these information should be used to increase accuracy of the model of the object and the current position of the robot. In other words, our framework employs SLAM approach. We also provide several real world implementations of our framework and compare them to illustrate the benefit of our framework. In particular, we install a depth camera DepthSense DS325 on a Katana robotic arm and use this system to simulate the navigation of the robotic arm for grasping. The comparison of our implementation confirms effectiveness of our framework.},
annote = {INCONCLUSIVE METHOD USED

DO NOT USE FOR REVIEW

PLEASE READ BACK},
author = {Wongwilai, Natchanon and Niparnan, Nattee and Sudsang, Attawith},
doi = {10.1109/CYBER.2014.6917453},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wongwilai, Niparnan, Sudsang - 2014 - SLAM-based grasping framework for robotic arm navigation and object model construction.pdf:pdf},
isbn = {9781479936687},
journal = {4th Annual IEEE International Conference on Cyber Technology in Automation, Control and Intelligent Systems, IEEE-CYBER 2014},
pages = {156--161},
title = {{SLAM-based grasping framework for robotic arm navigation and object model construction}},
year = {2014}
}
@article{Sawada2012,
abstract = {A method based on an Unscented Kalman Filter is presented for collision detection and control of parallel-structured two-link flexible manipulators. The exact dynamics of parallel-structured two-link flexible manipulators is described by nonlinear partial and ordinary differential equations having considerable complexity. Here, manipulators are modeled approximately by a two-link flexible manipulator consisting of a pair of flexible beams under the same boundary conditions as the original system. To discover the instant at which the flexible manipulator collides with an unknown obstacle, the innovation of the Unscented Kalman Filter - a nonlinear state estimator - is introduced. To control the manipulator, a sliding mode controller is employed. Under the normal conditions, the sliding mode controller generates control torques such that the tip position of the manipulator follows a given reference trajectory. However, when collision between the flexible manipulator and an obstacle is detected, the controller switches from position control to suspend control by changing the reference trajectory. The performance of the proposed collision detection algorithm and controller is demonstrated via two numerical simulations. {\textcopyright} 2012 ISSN 1349-4198.},
annote = {The authors present a technique of collision avoidance using unscented Kalman filter for a two-link flexible manipulators. The researchers use sliding mode controller to control the motion of the manipulator.

The authors investigate the use of extended Kalman filter to manage the uncertainty introduced by the flexible beams of the manipulator which affects the motion trajectory of the manipulator's end effector. They introduce a collision input into the observation model of the UKF. The collision is detected by a piezoelectric sensors attach at the base of the links. An abnormal reading from the piezoeletric sensors would trigger the collision input and change the parameters of the UKF to suspend control of the manipulator. 

They confirmed that, through two numerical simulation, the algorithm for their collision detection via UKF successfully increase efficiency.},
author = {Sawada, Yuichi and Kondo, Junki and Watanabe, Yusuke},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sawada, Kondo, Watanabe - 2012 - UKF-based collision detection and control of parallel-structured two-link flexible manipulators.pdf:pdf},
issn = {13494198},
journal = {International Journal of Innovative Computing, Information and Control},
keywords = {Collision detection,Flexible manipulator,Innovation,Sliding mode control,Unscented Kalman Filter},
number = {3 B},
pages = {2399--2413},
title = {{UKF-based collision detection and control of parallel-structured two-link flexible manipulators}},
volume = {8},
year = {2012}
}
@article{Bautin2010,
abstract = {For its own safety, a robot system should never find itself in a state where there is no feasible trajectory to avoid collision with an obstacle. Such a state is an Inevitable Collision State (ICS). The ICS concept is particularly useful for navigation in dynamic environments because it takes into account the future behaviour of the moving objects. Accordingly it requires a model of the future evolution of the environment. In the real-world, the future trajectories of the obstacles are generally unknown and only estimates are available. This paper introduces a probabilistic formulation of the ICS concept which incorporates uncertainty in the model of the future trajectories of the obstacles. It also presents two novel probabilistic ICS-checking algorithms that are compared with their deterministic counterpart.},
annote = {This paper is not useful for your review. It is useful, though, for your overall research on dynamic obstacle tracking.},
author = {Bautin, Antoine and Martinez-Gomez, Luis and Fraichard, Thierry},
doi = {10.1109/ROBOT.2010.5509233},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bautin, Martinez-Gomez, Fraichard - 2010 - Inevitable collision states A probabilistic perspective.pdf:pdf},
isbn = {9781424450381},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
keywords = {Collision avoidance,Dynamic environments,Inevitable collision states,Motion safety,Uncertainty},
pages = {4022--4027},
title = {{Inevitable collision states: A probabilistic perspective}},
year = {2010}
}
@article{Berenson2008,
abstract = {We present an optimization-based approach to grasping and path planning for mobile manipulators. We focus on pick-and-place operations, where a given object must be moved from its start configuration to its goal configuration by the robot. Given only the start and goal configurations of the object and a model of the robot and scene, our algorithm finds a grasp and a trajectory for the robot that will bring the object to its goal configuration. The algorithm consists of two phases: optimization and planning. In the optimization phase, the optimal robot configurations and grasp are found for the object in its start and goal configurations using a co-evolutionary algorithm. In the planning phase, a path is found connecting the two robot configurations found by the optimization phase using Rapidly-Exploring Random Trees (RRTs). We benchmark our algorithm and demonstrate it on a 10 DOF mobile manipulator performing complex pick-and-place tasks in simulation.},
annote = {DONT USE JUST IN REVIEW.
JUST SIMULATION},
author = {Berenson, D. and Kuffner, J. and Choset, H.},
doi = {10.1109/ROBOT.2008.4543365},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Skoglund et al. - 2010 - First Steps Towards a Robotic System for Flexible Volumetric Mapping of Indoor Environments(5).pdf:pdf},
isbn = {978-1-4244-1646-2},
issn = {1050-4729},
journal = {2008 IEEE International Conference on Robotics and Automation},
keywords = {Evolutionary Robotics,Fingers,Glass,Joining processes,Layout,Manipulation Planning,Motion and Path Planning,Motion planning,Robotics and automation,USA Councils,co-evolutionary algorithm,manipulators,mobile manipulator,mobile robots,optimisation,optimization-based approach,path planning,pick-and-place operation,rapidly-exploring random trees},
pages = {1187--1192},
title = {{An optimization approach to planning for mobile manipulation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4543365},
year = {2008}
}
@article{Likhachev2010,
annote = {Uses 7DOF robot manipulator. The paper present a search-based planning as an oppose to sampling-based motion planning. They use examples of motion planning in lower dimensionality problem or problems in low-dimensional manifold as a heuristic for motion planning in higher dimensional manifold. From this heuristic, they define motion primitives, a predefine motions of a single joint, and used them to minimize the cost function so that the most optimal path can be realized. This method eliminated the multiple solution to start-to-goal configuration by selecting the most feasible path that avoids collision which may not have the shortest path. They coined their searching-based planner as ARA*. ARA* is different from A* algorithm because A* always aims at getting into a goal configuration at the shortest travesal. ARA* is different in the sense because initially, the selection of path is based on the feasibility of getting into the goal configuration without any collision.

They use occupancy grid map to decrease the intractability of their algorithm so that the ARA motion planner produce the most optimum solution in path planning. They manage the uncertainty of multiple path solution by eliminating it using cost function as constraint to their path planning algorithm.

Validation: they validate their approach by simulating manipulation in a cluttered tabletop and conclude that their approach are only optimal for three degree of freedom pose (translational) rather than a ful six degree of freedom pose (translational in x,y, and z directions together with orientation about the x, y and z lines)
They also perform the same experimentation on a PR2 robot with 7DOF manipulator},
author = {Likhachev, Maxim},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Skoglund et al. - 2010 - First Steps Towards a Robotic System for Flexible Volumetric Mapping of Indoor Environments(2).pdf:pdf},
isbn = {9781424450404},
journal = {2010 IEEE International Conference on Robotics and Automation},
pages = {2902--2908},
title = {{Search-based Planning with Motion Primitives}},
url = {http://www.cs.berkeley.edu/{~}pabbeel/cs287-fa11/slides/Likhachev{\_}robschooltutorial{\_}oct10.pdf},
year = {2010}
}
@phdthesis{Soucy2005,
annote = {KIV THESIS. PLEASE COME BACK AGAIN},
author = {Soucy, M},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - manipulator path planning with multi resolution potential fields and fuzzy logic control-thesis.PDF.pdf:pdf},
title = {{Manipulator Path Planning with Multi-Resolution Potencial Fields and Fuzzy Logic Control}},
year = {2005}
}
@article{Petrovskaya2006,
abstract = {We consider the problem of autonomously estimating position and orientation of an object from tactile data. When initial uncertainty is high, estimation of all six parameters precisely is computationally expensive. We propose an efficient Bayesian approach that is able to estimate all six parameters in both unimodal and multimodal scenarios. The approach is termed scaling series sampling as it estimates the solution region by samples. It performs the search using a series of successive refinements, gradually scaling the precision from low to high. Our approach can be applied to a wide range of manipulation tasks. We demonstrate its portability on two applications: (1) manipulating a box and (2) grasping a door handle},
annote = {We consider the problem of autonomously estimat-
ing position and orientation of an object from tactile data. When initial uncertainty is high, estimation of all six parameters precisely is computationally expensive. We propose an efficient Bayesian approach that is able to estimate all six parameters in both unimodal and multimodal scenarios. The approach is termed Scaling Series sampling as it estimates the solution region by samples. It performs the search using a series of successive refinements, gradually scaling the precision from low to high. Our approach can be applied to a wide range of manipulation tasks. We demonstrate its portability on two applications: (1) manipulating a box and (2) grasping a door handle.
I.},
author = {Petrovskaya, Anna and Khatib, Oussama and Thrun, Sebastian and Ng, Andrew Y.},
doi = {10.1109/ROBOT.2006.1641793},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrovskaya et al. - 2006 - Bayesian estimation for autonomous object manipulation based on tactile sensors.pdf:pdf},
isbn = {0780395069},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
number = {May},
pages = {707--714},
title = {{Bayesian estimation for autonomous object manipulation based on tactile sensors}},
volume = {2006},
year = {2006}
}
@article{Rybski2012,
abstract = {Current manufacturing practices require complete physical separation between people and active industrial robots. These precautions ensure safety, but are inefficient in terms of time and resources, and place limits on the types of tasks that can be performed. In this paper, we present a real-time, sensor-based approach for ensuring the safety of people in close proximity to robots in an industrial workcell. Our approach fuses data from multiple 3D imaging sensors of different modalities into a volumetric evidence grid and segments the volume into regions corresponding to background, robots, and people. Surrounding each robot is a danger zone that dynamically updates according to the robot's position and trajectory. Similarly, surrounding each person is a dynamically updated safety zone. A collision between danger and safety zones indicates an impending actual collision, and the affected robot is stopped until the problem is resolved. We demonstrate and experimentally evaluate the concept in a prototype industrial workcell augmented with stereo and range cameras.},
annote = {Use this as an example and do not explain further. They use a variant occupancy grid map and handle uncertainty of the environment by fusing multiple sensor data using the evidence grid map.

This paper address the problem of working with manipulator at close proximity. The authors present a sensor fusion system to manage collision avoidance so that a working industrial robot is safer for human at close proximity. The fuse measurements from three sensors, a Swissranger SR4000's ranger and two Tyzx G3 EVS stero cameras. The sensors follows an eye-to-hand configuration. They present three segmentation after model of the environment based on the evidence grid is generated; the backgournd, the robot, and the human in the environment.},
author = {Rybski, Paul and Anderson-Sprecher, Peter and Huber, Daniel and Niessl, Chris and Simmons, Reid},
doi = {10.1109/IROS.2012.6386034},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Skoglund et al. - 2010 - First Steps Towards a Robotic System for Flexible Volumetric Mapping of Indoor Environments(7).pdf:pdf},
isbn = {9781467317375},
issn = {21530858},
journal = {IEEE International Conference on Intelligent Robots and Systems},
pages = {3612--3619},
title = {{Sensor fusion for human safety in industrial workcells}},
year = {2012}
}
@article{Li2015,
abstract = {Purpose – This paper aims to propose a new view planning method which can be used to calculate the next-best-view (NBV) for multiple manipulators simultaneously and build an automated three-dimensional (3D) object reconstruction system, which is based on the proposed method and can adapt to various industrial applications. Design/methodology/approach – The entire 3D space is encoded with octree, which marks the voxels with different tags. A set of candidate viewpoints is generated, filtered and evaluated. The viewpoint with the highest score is selected as the NBV. Findings – The proposed method is able to make the multiple manipulators, equipped with “eye-in-hand” RGB-D sensors, work together to accelerate the object reconstruction process. Originality/value – Compared to the existed approaches, the proposed method in this paper is fast, computationally efficient, has low memory cost and can be used in actual industrial productions where the multiple different manipulators exist. And, more notably, a new...},
annote = {KIV: might be carbage},
author = {Li, Liangzhi and Xiao, Nanfeng},
doi = {10.1108/IR-05-2015-0110},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Xiao - 2015 -.pdf:pdf},
issn = {0143-991X},
journal = {Industrial Robot: An International Journal},
keywords = {3D reconstruction,Industrial robot,Machine vision,Manipulators,Sensors,View planning},
number = {6},
pages = {533--543},
title = {+},
url = {http://www.emeraldinsight.com/doi/full/10.1108/IR-05-2015-0110},
volume = {42},
year = {2015}
}
@article{Afthnoi2013,
author = {Afthnoi, Rizqa and Rizae, Achmad and Susanto, Erwin$\backslash$},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Afthnoi, Rizae, Susanto - 2013 - Proportional Derivative Control Based Robot Arm System Using Microsoft Kinect.pdf:pdf},
isbn = {9781479912087},
journal = {Robotics, Biomimetics, and Intelligent Computational Systems (ROBIONETICS)},
keywords = {- proportional-derivative control,inverse kinematic,manipulator robot,microsoft kinect},
number = {November},
pages = {24 -- 27},
title = {{Proportional Derivative Control Based Robot Arm System Using Microsoft Kinect}},
year = {2013}
}
@article{Ranjbar2015,
abstract = {Robot path planning is an important part of the development of autonomous systems. Numerous strategies have been proposed in the literature regarding mobile robots but trajectory planning for manipulators is considerably more difficult since the entire structure can move and therefore produce collisions with surrounding obstacles. This paper presents an original solution and analytical comparison to path planning for manipulator arms. Path planning is executed in two parts: first, a global path is found to guide the end-effector in the environment using artificial potential fields and multi-resolution occupancy grids, then, a local path is determined for the entire robot structure by considering the kinematics of the robot as well as the repulsive forces of nearby obstacles in a fuzzy logic controller. Results are shown from a simulator that has been built for this purpose. The contribution of this research is to develop a robust solution for path planning with collision avoidance: one that can be used for various manipulator arms and environment configurations.},
annote = {DONT USE},
author = {Ranjbar, Babak and Mahmoodi, Javad and Karbasi, Hasan and Dashti, Gholam and Omidvar, Ali},
doi = {10.14257/ijunesst.2015.8.1.02},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ranjbar et al. - 2015 - Robot Manipulator Path Planning Based on Intelligent Multi- resolution Potential Field.pdf:pdf},
issn = {2005-4246},
journal = {International Journal Science and Technology},
keywords = {Robot path planning,artificial potential field,fuzzy logic control,robot manipulator},
number = {1},
pages = {11--26},
title = {{Robot Manipulator Path Planning Based on Intelligent Multi- resolution Potential Field}},
url = {http://dx.doi.org/10.14257/ijunesst.2015.8.1.02},
volume = {8},
year = {2015}
}
@article{Likhachev2014,
abstract = {In real world planning problems, time for deliberation is often limited. Anytime planners are well suited for these problems: they find a feasible solution quickly and then continually work on improving it until time runs out. In this paper we propose an anytime heuristic search, ARA*, which tunes its performance bound based on available search time. It starts by finding a suboptimal solution quickly using a loose bound, then tightens the bound progressively as time allows. Given enough time it finds a provably optimal solution. While improving its bound, ARA* reuses previous search efforts and, as a result, is significantly more efficient than other anytime search methods. In addition to our theoretical analysis, we demonstrate the practical utility of ARA* with experiments on a simulated robot kinematic arm and a dynamic path planning problem for an outdoor rover.},
author = {Likhachev, Maxim and Gordon, Geoff and Thrun, Sebastian},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Likhachev et al. - Unknown - ARA Anytime A with provable bounds on sub-optimality.pdf:pdf},
journal = {Science},
title = {{ARA *: Anytime A * with Provable Bounds on}},
url = {http://papers.nips.cc/paper/2382-ara-anytime-a-with-provable-bounds-on-sub-optimality.pdf https://papers.nips.cc/paper/2382-ara-anytime-a-with-provable-bounds-on-sub-optimality.pdf},
year = {2014}
}
@article{Du2014,
abstract = {This paper utilizes a human-robot interface system which incorporates particle filter (PF) and adaptive multispace transformation (AMT) to track the pose of the human hand for controlling the robot manipulator. This system employs a 3D camera (Kinect) to determine the orientation and the translation of the human hand. We use Camshift algorithm to track the hand. PF is used to estimate the translation of the human hand. Although a PF is used for estimating the translation, the translation error increases in a short period of time when the sensors fail to detect the hand motion. Therefore, a methodology to correct the translation error is required. What is more, to be subject to the perceptive limitations and the motor limitations, human operator is hard to carry out the high precision operation. This paper proposes an adaptive multispace transformation (AMT) method to assist the operator to improve the accuracy and reliability in determining the pose of the robot. The human-robot interface system was experimentally tested in a lab environment, and the results indicate that such a system can successfully control a robot manipulator.},
annote = {The motivation behind this paper is to introduce contactless and markerless control of a manipulator using computer vision. It is similar to visual servoing?

The researcher uses kinect to translate a human arm motion into a motion of a manipulator:

(1)Camshift to track hand position
(2)PF to estimate the hand position and orientation. The purpose of the PF is to handle noise error from the Kinect sensor and the accumulated error introduce from the Camshift method of tracking. 
and 
(3)Adaptive multispace transformation (AMT) method to translate the estimated pose of the human hand into the workspace of the manipulator. 

The robot inverse kinematics are solved numerically using Levenberg-Marquardt algorithm (LM algorithm)

The result was benchmark with research done by 
Kofman et al. “Teleoperation of a robot manipulator using a vision-based human-robot interface,”},
author = {Du, Guanglong and Zhang, Ping and Wang, Xueqian},
doi = {10.1155/2014/692165},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Du, Zhang, Wang - 2014 - Human-manipulator interface using particle filter.pdf:pdf},
issn = {1537-744X},
journal = {TheScientificWorldJournal},
pages = {692165},
pmid = {24757430},
title = {{Human-manipulator interface using particle filter.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3976865{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {2014},
year = {2014}
}
@article{Venator2013,
abstract = {Industrial robotic manipulators have successfully automated many stationary factory tasks, but there exist many other tasks which could be automated given a mobile platform. One such task is kitting, the process of gathering the constituent elements of a larger unit (the {\&}{\#}x201C;kit{\&}{\#}x201D;) from inventory. ABBY is a prototype of a low-price industrial mobile manipulator platform chiefly composed of an ABB IRB-120 industrial robotic manipulator and an Invacare electric wheelchair base. Use of the Robot Operating System (ROS) and ROS Industrial facilitated development and drivers for ABB industrial manipulators have been contributed back to the ROS Industrial project. ABBY is designed to autonomously navigate a factory to populate and deliver kits to workstations. This paper describes the prototype robot constructed to pursue this research, including the use of ROS and ROS Industrial to facilitate and accelerate system development.},
annote = {Use this paper as a good example of manipulator attached to a mobile platform

SLAM solution are not at manipulation level},
author = {Venator, Edward and Lee, Gregory S. and Newman, Wyatt},
doi = {10.1109/CoASE.2013.6653969},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Skoglund et al. - 2010 - First Steps Towards a Robotic System for Flexible Volumetric Mapping of Indoor Environments(8).pdf:pdf},
isbn = {9781479915156},
issn = {21618070},
journal = {IEEE International Conference on Automation Science and Engineering},
pages = {324--329},
title = {{Hardware and software architecture of ABBY: An industrial mobile manipulator}},
year = {2013}
}
@article{Payeur1997,
abstract = {Probabilistic occupancy grids have proved to be very useful for$\backslash$nworkspace modeling in 2D environments. Due to the expansion of$\backslash$ncomputational load, this approach was not tractable for mapping a 3D$\backslash$nenvironment in real applications. In this paper, the original occupancy$\backslash$ngrid scheme is revisited and a generic closed-form function is$\backslash$nintroduced to avoid numerical computation of probabilities for a range$\backslash$nsensor with Gaussian error distribution. Occupancy probabilities are$\backslash$ncomputed and stored in a multiresolution octree for improved performance$\backslash$nand compactness. Occupancy models are built in local reference frames$\backslash$nand linked to a global reference frame through uncertain spatial$\backslash$nrelationships that can be updated dynamically. This scheme is used for$\backslash$nbuilding a 3D map in a telerobotic maintenance application of electric$\backslash$npower lines where perturbations may cause motion of object$\backslash$nassembly},
annote = {Use this paper as an introduction to occupancy grid map by Elfes.

Address that the paper use octree based representation of occupancy grid map to reduce computational load so that the grid map can be used to represent 3D scenes

The paper validated their method by simulation},
author = {Payeur, P. and Hebert, P. and Laurendeau, D. and Gosselin, Cl{\'{e}}ment M.},
doi = {10.1109/ROBOT.1997.614315},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Payeur et al. - 1997 - Probabilistic octree modeling of a 3D dynamic environment.pdf:pdf},
isbn = {0-7803-3612-7},
journal = {Proceedings of International Conference on Robotics and Automation},
number = {April},
pages = {1289--1296},
title = {{Probabilistic octree modeling of a 3D dynamic environment}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=614315},
volume = {2},
year = {1997}
}
@article{Matuszek2011,
abstract = {This paper presents Gambit, a custom, mid-cost 6-DoF robot manipulator system that can play physical board games against human opponents in non-idealized environments. Historically, unconstrained robotic manipulation in board games has often proven to be more challenging than the underlying game reasoning, making it an ideal testbed for small-scale manipulation. The Gambit system includes a low-cost Kinect-style visual sensor, a custom manipulator, and state-of-the-art learning algorithms for automatic detection and recognition of the board and objects on it. As a use-case, we describe playing chess quickly and accurately with arbitrary, uninstrumented boards and pieces, demonstrating that Gambit's engineering and design represent a new state-of-the-art in fast, robust tabletop manipulation.},
annote = {Use in introduction as an example for occupancy grid map usage to manage uncertainty in workspace

DO NOT ELABORATE MUCH

a six degree of freedom custom robot that plays chess. The visual feedback uses PrimeSense camera, an RGB-D sensor with eye-in-hand configuration.},
author = {Matuszek, Cynthia and Mayton, Brian and Aimi, Roberto and Deisenroth, Marc Peter and Bo, Liefeng and Chu, Robert and Kung, Mike and {Le Grand}, Louis and Smith, Joshua R. and Fox, Dieter},
doi = {10.1109/ICRA.2011.5980528},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Skoglund et al. - 2010 - First Steps Towards a Robotic System for Flexible Volumetric Mapping of Indoor Environments(4).pdf:pdf},
isbn = {9781612843865},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
keywords = {Mechanism design of manipulators,Physical human robot interaction},
pages = {4291--4297},
title = {{Gambit: An autonomous chess-playing robotic system}},
year = {2011}
}
@article{Chiu2015,
annote = {This will be used to support Song et al. (2013)},
author = {Chiu, Yi-fu},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chiu - 2015 - Vision-Based Grasp Planning and Experiments of a Mobile Manipulator.pdf:pdf},
keywords = {mobile manipulation,robot grasping,visual navigation,visual servoing},
number = {4},
pages = {257--260},
title = {{Vision-Based Grasp Planning and Experiments of a Mobile Manipulator}},
volume = {1},
year = {2015}
}
@article{Budiharto2014,
annote = {Not to be included in review
But please read as a primer to SIFT},
author = {Budiharto, Widodo},
doi = {10.1109/ICAMechS.2014.6911587},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Budiharto - 2014 - Robust vision-based detection and grasping object for manipulator using SIFT keypoint detector.pdf:pdf},
isbn = {9781479963812},
issn = {23250690},
journal = {International Conference on Advanced Mechatronic Systems, ICAMechS},
keywords = {Bayesian filter,FLANN,SIFT Keypoint,manipulator,matching,stereo vision},
pages = {448--452},
title = {{Robust vision-based detection and grasping object for manipulator using SIFT keypoint detector}},
year = {2014}
}
@article{Li2008,
abstract = {This paper presents a simulator to simulating two key problems-underwater perception and autonomous manipulation o In the simulator a controller-observer strategy is proposed. A new SLAM (Simultaneous Localization and Mapping) algorithm - UKF (Unscented Kalman Filter) is used to estimate the state of UVMS (Underwater Vehicle Manipulator Systems) and the target object. 3D Simulation results show that the new SLAM algorithm can get the optimal estimation of state of UVMS and the target object, and the end-effector of manipulator can reach the desired object and the accuracy is centimeter level.},
annote = {KIV},
author = {Li, Qiang and Zhang, Qifeng and Wang, Xiaohui},
doi = {10.1109/OCEANSKOBE.2008.4531000},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Zhang, Wang - 2008 - Research on dynamic simulation of underwater vehicle manipulator systems.pdf:pdf},
isbn = {9781424421268},
journal = {OCEANS'08 MTS/IEEE Kobe-Techno-Ocean'08 - Voyage toward the Future, OTO'08},
keywords = {Autonomous manipulation,Position estimation,SLAM,UKF,UVMS},
title = {{Research on dynamic simulation of underwater vehicle manipulator systems}},
year = {2008}
}
