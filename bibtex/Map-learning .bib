Automatically generated by Mendeley Desktop 1.19.5
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Yan2015,
abstract = {Distribution of land cover has a profound impact on the climate and environment; mapping the land cover patterns from global, regional to local scales are important for scientists and authorities to yield better monitoring of the changing world. Satellite remote sensing has been demonstrated as an efficient tool to monitor the land cover patterns for a large spatial extent. Nevertheless, the demand on land cover maps at a finer scale (especially in urban areas) has been raised with evidence by numerous biophysical and socio-economic studies. This paper reviews the small-footprint LiDAR sensor - one of the latest high resolution airborne remote sensing technologies, and its application on urban land cover classification. While most of the early researches focus on the analysis of geometric components of 3D LiDAR data point clouds, there has been an increasing interest in investigating the use of intensity data, waveform data and multi-sensor data to facilitate land cover classification and object recognition in urban environment. In this paper, the advancement of airborne LiDAR technology, including data configuration, feature spaces, classification techniques, and radiometric calibration/correction is reviewed and discussed. The review mainly focuses on the LiDAR studies conducted during the last decade with an emphasis on identification of the approach, analysis of pros and cons, investigating the overall accuracy of the technology, and how the classification results can serve as an input for different urban environmental analyses. Finally, several promising directions for future LiDAR research are highlighted, in hope that it will pave the way for the applications of urban environmental modeling and assessment at a finer scale and a greater extent.},
author = {Yan, Wai Yeung and Shaker, Ahmed and El-Ashmawy, Nagwa},
doi = {10.1016/j.rse.2014.11.001},
file = {::},
isbn = {0034-4257},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Airborne LiDAR,Full-waveform,Land cover classification,Land cover mapping,Laser scanning,LiDAR intensity,Radiometric calibration,Radiometric correction,Urban analysis,Urban environment},
pages = {295--310},
publisher = {Elsevier Inc.},
title = {{Urban land cover classification using airborne LiDAR data: A review}},
url = {http://dx.doi.org/10.1016/j.rse.2014.11.001},
volume = {158},
year = {2015}
}
@article{Pham2016,
abstract = {There are now a wide range of techniques that can be combined for image analysis. These include the use of object-based classifications rather than pixel-based classifiers, the use of LiDAR to determine vegetation height and vertical structure, as well terrain variables such as topographic wetness index and slope that can be calculated using GIS. This research investigates the benefits of combining these techniques to identify individual tree species. A QuickBird image and low point density LiDAR data for a coastal region in New Zealand was used to examine the possibility of mapping Pohutukawa trees which are regarded as an iconic tree in New Zealand. The study area included a mix of buildings and vegetation types. After image and LiDAR preparation, single tree objects were identified using a range of techniques including: a threshold of above ground height to eliminate ground based objects; Normalised Difference Vegetation Index and elevation difference between the first and last return of LiDAR data to distinguish vegetation from buildings; geometric information to separate clusters of trees from single trees, and treetop identification and region growing techniques to separate tree clusters into single tree crowns. Important feature variables were identified using Random Forest, and the Support Vector Machine provided the classification. The combined techniques using LiDAR and spectral data produced an overall accuracy of 85.4{\%} (Kappa 80.6{\%}). Classification using just the spectral data produced an overall accuracy of 75.8{\%} (Kappa 67.8{\%}). The research findings demonstrate how the combining of LiDAR and spectral data improves classification for Pohutukawa trees.},
author = {Pham, Lien T.H. and Brabyn, Lars and Ashraf, Salman},
doi = {10.1016/j.jag.2016.03.015},
file = {::},
issn = {03032434},
journal = {International Journal of Applied Earth Observation and Geoinformation},
keywords = {LiDAR,Object-based classification,Pohutukawa,QuickBird,Random forest,Support vector machine,object-based classification},
pages = {187--197},
publisher = {Elsevier B.V.},
title = {{Combining QuickBird, LiDAR, and GIS topography indices to identify a single native tree species in a complex landscape using an object-based classification approach}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0303243416300460},
volume = {50},
year = {2016}
}
@article{Liu2016,
abstract = {We address the problem of high speed autonomous navigation of quadrotor micro aerial vehicles with limited onboard sensing and computation. In particular, we propose a dual range planning horizon method to safely and quickly navigate quadrotors to specified goal locations in previously unknown and unstructured environments. In each planning epoch, a short-range planner uses a local map to generate a new trajectory. At the same time, a safe stopping policy is found. This allows the robot to come to an emergency halt when necessary. Our algorithm guarantees collision avoidance and demonstrates important advances in real-time planning. First, our novel short range planning method allows us to generate and re-plan trajectories that are dynamically feasible, comply with state and input constraints, and avoid obstacles in real-time. Further, previous planning algorithms abstract away the obstacle detection problem by assuming the instantaneous availability of geometric information about the environment. In contrast, our method addresses the challenge of using the raw sensor data to form a map and navigate in real-time. Finally, in addition to simulation examples, we provide physical experiments that demonstrate the entire algorithmic pipeline from obstacle detection to trajectory execution.},
author = {Liu, Sikang and Watterson, Michael and Tang, Sarah and Kumar, Vijay},
doi = {10.1109/ICRA.2016.7487284},
file = {::},
isbn = {9781467380263},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
pages = {1484--1491},
title = {{High speed navigation for quadrotors with limited onboard sensing}},
volume = {2016-June},
year = {2016}
}
@article{Droeschel2016,
abstract = {Micro aerial vehicles, such as multirotors, are particularly well suited for the autonomous monitoring, inspection, and surveillance of buildings, e.g., for maintenance or disaster management. Key prerequisites for the fully autonomous operation of micro aerial vehicles are real-time obstacle detection and planning of collision-free trajectories. In this article, we propose a complete system with a multimodal sensor setup for omnidirectional obstacle perception consisting of a three-dimensional (3D) laser scanner, two stereo camera pairs, and ultrasonic distance sensors. Detected obstacles are aggregated in egocentric local multiresolution grid maps. Local maps are efficiently merged in order to simultaneously build global maps of the environment and localize in these. For autonomous navigation, we generate trajectories in a multilayered approach: from mission planning over global and local trajectory planning to reactive obstacle avoidance. We evaluate our approach and the involved components in simulation and with the real autonomous micro aerial vehicle. Finally, we present the results of a complete mission for autonomously mapping a building and its surroundings.},
archivePrefix = {arXiv},
arxivId = {10.1.1.91.5767},
author = {Droeschel, David and Nieuwenhuisen, Matthias and Beul, Marius and Holz, Dirk and St{\"{u}}ckler, J{\"{o}}rg and Behnke, Sven},
doi = {10.1002/rob.21603},
eprint = {10.1.1.91.5767},
file = {::},
isbn = {9783902661623},
issn = {15564967},
journal = {Journal of Field Robotics},
number = {4},
pages = {451--475},
pmid = {22164016},
title = {{Multilayered Mapping and Navigation for Autonomous Micro Aerial Vehicles}},
volume = {33},
year = {2016}
}
@article{Meesuk2015,
abstract = {Remote Sensing technologies are capable of providing high-resolution spatial data needed to set up advanced flood simulation models. Amongst them, aerial Light Detection and Ranging (LiDAR) surveys or Airborne Laser Scanner (ALS) systems have long been used to provide digital topographic maps. Nowadays, Remote Sensing data are commonly used to create Digital Terrain Models (DTMs) for detailed urban-flood modelling. However, the difficulty of relying on top-view LiDAR data only is that it cannot detect whether passages for floodwaters are hidden underneath vegetated areas or beneath overarching structures such as roads, railroads, and bridges. Such (hidden) small urban features can play an important role in urban flood propagation. In this paper, a complex urban area of Kuala Lumpur, Malaysia was chosen as a study area to simulate the extreme flooding event that occurred in 2003. Three different DTMs were generated and used as input for a two-dimensional (2D) urban flood model. A top-view LiDAR approach was used to create two DTMs: (i) a standard LiDAR-DTM and (ii) a Filtered LiDAR-DTM taking into account specific ground-view features. In addition, a Structure from Motion (SfM) approach was used to detect hidden urban features from a sequence of ground-view images; these ground-view SfM data were then combined with top-view Filtered LiDAR data to create (iii) a novel Multidimensional Fusion of Views-Digital Terrain Model (MFV-DTM). These DTMs were then used as a basis for the 2D urban flood model. The resulting dynamic flood maps are compared with observations at six measurement locations. It was found that when applying only top-view DTMs as input data, the flood simulation results appear to have mismatches in both floodwater depths and flood propagation patterns. In contrast, when employing the top-ground-view fusion approach (MFV-DTM), the results not only show a good agreement in floodwater depth, but also simulate more correctly the floodwater dynamics around small urban feature. Overall, the new multi-view approach of combining top-view LiDAR data with ground-view SfM observations shows a good potential for creating an accurate digital terrain map which can be then used as an input for a numerical urban flood model.},
author = {Meesuk, Vorawit and Vojinovic, Zoran and Mynett, Arthur E. and Abdullah, Ahmad F.},
doi = {10.1016/j.advwatres.2014.11.008},
file = {::},
isbn = {0309-1708},
issn = {03091708},
journal = {Advances in Water Resources},
keywords = {Digital terrain model (DTM),High-resolution topographic information,Light detection and ranging (LiDAR),Multidimensional fusion of views (MFV),Structure from motion (SfM),Urban flood modelling (UFM)},
pages = {105--117},
publisher = {Elsevier Ltd},
title = {{Urban flood modelling combining top-view LiDAR data with ground-view SfM observations}},
url = {http://dx.doi.org/10.1016/j.advwatres.2014.11.008},
volume = {75},
year = {2015}
}
@article{Mutz2016,
abstract = {In this paper, we present an end-to-end framework for precise large-scale mapping with applications in autonomous driving. In special, the problem of mapping complex environments, with features changing from tree-lined streets to urban areas with dense traffic, is studied. The robotic car is equipped with an odometry sensor, a 3D LiDAR Velodyne HDL-32E, a IMU, and a low cost GPS, and the data generated by these sensors are integrated in a pose-based GraphSLAM estimator. A new strategy for identification and correction of odometry data using evolutionary algorithms is presented. This new strategy makes odometry data significantly more consistent with GPS. Loop closures are detected using GPS data, and GICP, a 3D point cloud registration algorithm, is used to estimate the displacement between the different travels over the same region. After path estimation, 3D LiDAR data is used to build an occupancy grid mapping of the environment. A detailed mathematical description of how occupancy evidence can be calculated from the point clouds is given, and a submapping strategy to handle memory limitations is presented as well. The proposed framework is tested in three real world environments with different sizes, and features: a parking lot, a university beltway, and a city neighborhood. In all cases, satisfactory maps were built, with precise loop closures even when the vehicle traveled long distances between them.},
author = {Mutz, Filipe and Veronese, Lucas P. and Oliveira-Santos, Thiago and {De Aguiar}, Edilson and {Auat Cheein}, Fernando A. and {Ferreira De Souza}, Alberto},
doi = {10.1016/j.eswa.2015.10.045},
file = {::},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Autonomous vehicles,GraphSLAM,Mapping,Robotics,SLAM},
pages = {439--462},
publisher = {Elsevier Ltd},
title = {{Large-scale mapping in complex field scenarios using an autonomous car}},
url = {http://dx.doi.org/10.1016/j.eswa.2015.10.045},
volume = {46},
year = {2016}
}
@article{Lee2017,
abstract = {A critical problem in mapping data is the frequent updating of large data sets. To solve this problem, the updating of small-scale data based on large-scale data is very effective. Various map generalization techniques, such as simplification, displacement, typification, elimination, and aggregation, must therefore be applied. In this study, we focused on the elimination and aggregation of the building layer, for which each building in a large scale was classified as “0-eliminated,” “1-retained,” or “2-aggregated.” Machine-learning classification algorithms were then used for classifying the buildings. The data of 1:1000 scale and 1:25,000 scale digital maps obtained from the National Geographic Information Institute were used. We applied to these data various machine-learning classification algorithms, including naive Bayes (NB), decision tree (DT), k-nearest neighbor (k-NN), and support vector machine (SVM). The overall accuracies of each algorithm were satisfactory: DT, 88.96{\%}; k-NN, 88.27{\%}; SVM, 87.57{\%}; and NB, 79.50{\%}. Although elimination is a direct part of the proposed process, generalization operations, such as simplification and aggregation of polygons, must still be performed for buildings classified as retained and aggregated. Thus, these algorithms can be used for building classification and can serve as preparatory steps for building generalization.},
author = {Lee, Jaeeun and Jang, Hanme and Yang, Jonghyeon and Yu, Kiyun},
doi = {10.3390/ijgi6100309},
file = {::},
issn = {2220-9964},
journal = {ISPRS International Journal of Geo-Information},
keywords = {aggregation,building generalization,classification,elimination,map generalization},
number = {10},
pages = {309},
title = {{Machine Learning Classification of Buildings for Map Generalization}},
url = {http://www.mdpi.com/2220-9964/6/10/309},
volume = {6},
year = {2017}
}
@article{Droeschel2016a,
author = {Droeschel, David and Behnke, Sven},
doi = {10.1007/978-3-319-08338-4},
file = {::},
isbn = {978-3-319-08337-7},
issn = {21945357},
number = {January},
title = {{Intelligent Autonomous Systems 13}},
url = {http://link.springer.com/10.1007/978-3-319-08338-4},
volume = {302},
year = {2016}
}
@article{Fermin-Leon2016,
abstract = {In this work we address the problem of trajectory planning in Graph SLAM. We propose the use of Expected Value of the Final Uncertainty, which summarizes all the possible uncertainties that should be considered. In fully explored environments, this is used to determine the most reliable path to the final position. In partially explored environments, this criteria quantifies the reliability of the path planned in the free space. Tests demonstrate its ability to avoid unreliable paths in fully explored environments as compared to other uncertainty based criteria. In the exploration scenario, potential paths not present in the original graph are proposed using Voronoi Diagram of the space ahead observed by the sensors. A cost function is proposed considering the length of the path as well as the expected final uncertainty, thus including potentially shorter, but still reliable paths. Tests demonstrate the shortest path is preferred as long as it contains loop closures with low uncertainty.},
author = {Fermin-Leon, L. and Neira, J. and Castellanos, J. A.},
doi = {10.1109/IROS.2016.7759676},
file = {::},
isbn = {9781509037629},
issn = {21530866},
journal = {IEEE International Conference on Intelligent Robots and Systems},
pages = {4594--4601},
title = {{Path planning in graph SLAM using expected uncertainty}},
volume = {2016-Novem},
year = {2016}
}
@article{Kostavelis2015,
abstract = {The evolution of contemporary mobile robotics has given thrust to a series of additional conjunct technologies. Of such is the semantic mapping, which provides an abstraction of space and a means for human-robot communication. The recent introduction and evolution of semantic mapping motivated this survey, in which an explicit analysis of the existing methods is sought. The several algorithms are categorized according to their primary characteristics, namely scalability, inference model, temporal coherence and topological map usage. The applications involving semantic maps are also outlined in the work at hand, emphasizing on human interaction, knowledge representation and planning. The existence of publicly available validation datasets and benchmarking, suitable for the evaluation of semantic mapping techniques is also discussed in detail. Last, an attempt to address open issues and questions is also made.},
author = {Kostavelis, Ioannis and Gasteratos, Antonios},
doi = {10.1016/j.robot.2014.12.006},
file = {::},
isbn = {0921-8890},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {Human-robot interaction,Knowledge representation,Mobile robots,Object recognition,Place recognition,Planning,Semantic map,Temporal coherence,Topological map},
pages = {86--103},
publisher = {Elsevier B.V.},
title = {{Semantic mapping for mobile robotics tasks: A survey}},
url = {http://dx.doi.org/10.1016/j.robot.2014.12.006},
volume = {66},
year = {2015}
}
@article{Mur-Artal2015b,
abstract = {In the last years several direct (i.e. featureless) monocular SLAM approaches have appeared showing impressive semi-dense or dense scene reconstructions. These works have questioned the need of features, in which consolidated SLAM techniques of the last decade were based. In this paper we present a novel feature-based monocular SLAM system that is more robust, gives more accurate camera poses, and obtains comparable or better semi-dense reconstructions than the cur- rent state of the art. Our semi-dense mapping operates over keyframes, optimized by local bundle adjustment, allowing to obtain accurate triangulations from wide baselines. Our novel method to search correspondences, the measurement fusion and the inter-keyframe depth consistency tests allow to obtain clean reconstructions with very few outliers. Against the current trend in direct SLAM, our experiments show that by decoupling the semi-dense reconstruction from the trajectory computation, the results obtained are better. This opens the discussion on the benefits of features even if a semi-dense reconstruction is desired.},
author = {Mur-Artal, Raul and Tardos, Juan},
doi = {10.15607/RSS.2015.XI.041},
file = {::},
isbn = {9780992374716},
issn = {10504729},
journal = {Robotics: Science and Systems XI},
title = {{Probabilistic Semi-Dense Mapping from Highly Accurate Feature-Based Monocular SLAM}},
url = {http://www.roboticsproceedings.org/rss11/p41.pdf},
year = {2015}
}
@article{GhaffariJadidi2017,
abstract = {Most of the existing robotic exploration schemes use occupancy grid representations and geometric targets known as frontiers. The occupancy grid representation relies on the assumption of independence between grid cells and ignores structural correlations present in the environment. We develop a Gaussian processes (GPs) occupancy mapping technique that is computationally tractable for online map building due to its incremental formulation and provides a continuous model of uncertainty over the map spatial coordinates. The standard way to represent geometric frontiers extracted from occupancy maps is to assign binary values to each grid cell. We extend this notion to novel probabilistic frontier maps computed efficiently using the gradient of the GP occupancy map. We also propose a mutual information-based greedy exploration technique built on that representation that takes into account all possible future observations. A major advantage of high-dimensional map inference is the fact that such techniques require fewer observations, leading to a faster map entropy reduction during exploration for map building scenarios. Evaluations using the publicly available datasets show the effectiveness of the proposed framework for robotic mapping and exploration tasks.},
author = {{Ghaffari Jadidi}, Maani and {Valls Miro}, Jaime and Dissanayake, Gamini},
doi = {10.1007/s10514-017-9668-3},
file = {::},
issn = {15737527},
journal = {Autonomous Robots},
keywords = {Autonomous navigation,Exploration,Gaussian processes,Mapping,Mutual information},
number = {2},
pages = {1--18},
publisher = {Springer US},
title = {{Gaussian processes autonomous mapping and exploration for range-sensing mobile robots}},
volume = {42},
year = {2017}
}
@misc{Meyer2003,
abstract = {This article reviews map-learning and path-planning strategies within the context of map-based navigation in mobile robots. Concerning map-learning, it distinguishes metric maps from topological maps and describes procedures that help maintain the coherency of these maps. Concerning path-planning, it distinguishes continuous from discretized spaces and describes procedures applicable when the execution of a plan fails. It insists on the need for an integrated conception of such procedures, which must be tightly tailored to the specific robot that is used, notably to the capacities and limitations of its sensory-motor equipment, and to the specific environment that is experienced. A hierarchy of navigation strategies is outlined in the discussion, together with the sort of adaptive capacities each affords to cope with unexpected obstacles or dangers encountered on an animat or robot's way to its goal. {\textcopyright} 2003 Elsevier B.V. All rights reserved.},
author = {Meyer, Jean Arcady and Filliat, David},
booktitle = {Cognitive Systems Research},
doi = {10.1016/S1389-0417(03)00007-X},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meyer, Filliat - 2003 - Map-based navigation in mobile robots II. A review of map-learning and path-planning strategies.pdf:pdf},
isbn = {1389-0417},
issn = {13890417},
keywords = {Autonomous mobile robot,Map-based navigation,Map-learning,Path-planning},
number = {4},
pages = {283--317},
title = {{Map-based navigation in mobile robots: II. A review of map-learning and path-planning strategies}},
volume = {4},
year = {2003}
}
@article{Jjumba2016,
abstract = {Many geographic processes evolve in a three dimensional space and time continuum. However, when they are represented with the aid of geographic information systems (GIS) or geosimulation models they are modelled in a framework of two-dimensional space with an added temporal component. The objective of this study is to propose the design and implementation of voxel-based automata as a methodological approach for representing spatial processes evolving in the four-dimensional (4D) space–time domain. Similar to geographic automata models which are developed to capture and forecast geospatial processes that change in a two-dimensional spatial framework using cells (raster geospatial data), voxel automata rely on the automata theory and use three-dimensional volumetric units (voxels). Transition rules have been developed to represent various spatial processes which range from the movement of an object in 3D to the diffusion of airborne particles and landslide simulation. In addition, the proposed 4D models demonstrate that complex processes can be readily reproduced from simple transition functions without complex methodological approaches. The voxel-based automata approach provides a unique basis to model geospatial processes in 4D for the purpose of improving representation, analysis and understanding their spatiotemporal dynamics. This study contributes to the advancement of the concepts and framework of 4D GIS.},
author = {Jjumba, Anthony and Dragi{\'{c}}evi{\'{c}}, Suzana},
doi = {10.1016/j.isprsjprs.2016.01.017},
file = {::},
issn = {09242716},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {4D GIS,Geographic automata systems,Geospatial processes,Spatiotemporal modelling,Voxel,Voxel automata},
pages = {206--216},
title = {{Towards a voxel-based geographic automata for the simulation of geospatial processes}},
volume = {117},
year = {2016}
}
@article{Asvadi2015,
author = {Asvadi, Alireza and Peixoto, Paulo and Nunes, Urbano},
file = {::},
journal = {The second Iberian Robotics Conference (ROBOT)},
keywords = {dynamic environ-,ment,motion detection,piecewise surface,velodyne perception,voxel representation},
title = {{Two-Stage Static / Dynamic Environment Modeling Using Voxel Representation}},
year = {2015}
}
@article{Mccormac2017,
abstract = {Ever more robust, accurate and detailed mapping using visual sensing has proven to be an enabling factor for mobile robots across a wide variety of applications. For the next level of robot intelligence and intuitive user interaction, maps need to extend beyond geometry and appearance — they need to contain semantics. We address this challenge by combining Convolutional Neural Networks (CNNs) and a state-of-the-art dense Simultaneous Localisation and Mapping (SLAM) system, ElasticFusion, which provides long-term dense correspondences between frames of indoor RGB-D video even during loopy scanning trajectories. These correspondences allow the CNN's semantic predictions from multiple view points to be proba-bilistically fused into a map. This not only produces a useful semantic 3D map, but we also show on the NYUv2 dataset that fusing multiple predictions leads to an improvement even in the 2D semantic labelling over baseline single frame predictions. We also show that for a smaller reconstruction dataset with larger variation in prediction viewpoint, the improvement over single frame segmentation increases. Our system is efficient enough to allow real-time interactive use at frame-rates of ≈25Hz.},
archivePrefix = {arXiv},
arxivId = {1609.05130},
author = {Mccormac, John and Handa, Ankur and Davison, Andrew J. and Leutenegger, Stefan},
doi = {10.1109/ICRA.2017.7989538},
eprint = {1609.05130},
file = {::},
isbn = {978-1-5090-4633-1},
issn = {08936080},
journal = {International Conference on Robotics and Automation (ICRA)},
keywords = {Semantic Scene Understanding,SLAM,Object detection},
pages = {4628--4635},
pmid = {21655600},
title = {{SemanticFusion: Dense 3D Semantic Mapping with Convolutional Neural Networks}},
url = {https://www.doc.ic.ac.uk/{~}sleutene/publications/Semanticfusion{\_}ICRA17{\_}Final.pdf},
year = {2017}
}
@article{He2016,
abstract = {The rapid and accurate assessment of building damage states using only post-event remote sensing data is critical when performing loss estimation in earthquake emergency response. Damaged roof detection is one of the most efficient methods of assessing building damage. In particular, airborne LiDAR is often used to detect roofs damaged by earthquakes, especially for certain damage types, due to its ability to rapidly acquire accurate 3D information on individual roofs. Earthquake-induced roof damages are categorized into surface damages and structural damages based on the geometry features of the debris and the roof structure. However, recent studies have mainly focused on surface damage; little research has been conducted on structural damage. This paper presents an original 3D shape descriptor of individual roofs for detecting roofs with surface damage and roofs exhibiting structural damage by identifying spatial patterns of compact and regular contours for intact roofs, as well as jagged and irregular contours for damaged roofs. The 3D shape descriptor is extracted from building contours derived from airborne LiDAR point clouds. First, contour clusters are extracted from contours that are generated from a dense DSM of individual buildings derived from point clouds. Second, the shape chaos indexes of contour clusters are computed as the information entropy through a contour shape similarity measurement between two contours in a contour cluster. Finally, the 3D shape descriptor is calculated as the weighted sum of the shape chaos index of each contour cluster corresponding to an individual roof. Damaged roofs are detected solely using the 3D shape descriptor with the maximum entropy threshold. Experiments using post-event airborne LiDAR point clouds of the 2010 Haiti earthquake suggest that the proposed damaged roof detection technique using the proposed 3D shape descriptor can detect both roofs exhibiting surface damage and roofs exhibiting structural damage with a high accuracy.},
author = {He, Meizhang and Zhu, Qing and Du, Zhiqiang and Hu, Han and Ding, Yulin and Chen, Min},
doi = {10.3390/rs8030189},
file = {::},
isbn = {8615827108512},
issn = {20724292},
journal = {Remote Sensing},
keywords = {3D shape descriptor,Building damage detection,Contour cluster,Entropy,Shape similarity},
number = {3},
title = {{A 3D shape descriptor based on contour clusters for damaged roof detection using airborne LiDAR point clouds}},
volume = {8},
year = {2016}
}
@article{Jadidi2017,
abstract = {In this paper, we develop a high-dimensional map building technique that incorporates raw pixelated semantic measurements into the map representation. The proposed technique uses Gaussian Processes (GPs) multi-class classification for map inference and is the natural extension of GP occupancy maps from binary to multi-class form. The technique exploits the continuous property of GPs and, as a result, the map can be inferred with any resolution. In addition, the proposed GP Semantic Map (GPSM) learns the structural and semantic correlation from measurements rather than resorting to assumptions, and can flexibly learn the spatial correlation as well as any additional non-spatial correlation between map points. We extend the OctoMap to Semantic OctoMap representation and compare with the GPSM mapping performance using NYU Depth V2 dataset. Evaluations of the proposed technique on multiple partially labeled RGBD scans and labels from noisy image segmentation show that the GP semantic map can handle sparse measurements, missing labels in the point cloud, as well as noise corrupted labels.},
annote = {Please do not cite for any literature you are writing. However please use their references:},
archivePrefix = {arXiv},
arxivId = {1707.01532},
author = {Jadidi, Maani Ghaffari and Gan, Lu and Parkison, Steven A. and Li, Jie and Eustice, Ryan M.},
eprint = {1707.01532},
file = {::},
keywords = {semantic{\_}references},
mendeley-tags = {semantic{\_}references},
title = {{Gaussian Processes Semantic Map Representation}},
url = {http://arxiv.org/abs/1707.01532},
year = {2017}
}
@article{Filliat2003,
author = {Filliat, D and Meyer, J.-A.},
file = {:home/rais/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Filliat, Meyer - 2003 - Map-based navigation in mobile robots - {\{}I{\}}. A review of localisation strategies.pdf:pdf},
journal = {Journal of Cognitive Systems Research},
keywords = {autonomous mobile robot,map-based navigation,map-learning,path-planning},
number = {4},
pages = {243--282},
title = {{Map-based navigation in mobile robots - {\{}I{\}}. A review of localisation strategies}},
volume = {4},
year = {2003}
}
@article{Whelan2015,
abstract = {We present a novel approach to real-time dense visual SLAM. Our system is capable of capturing comprehensive dense globally consistent surfel-based maps of room scale environments explored using an RGB-D camera in an incremental online fashion, without pose graph optimisation or any postprocessing steps. This is accomplished by using dense frame-tomodel camera tracking and windowed surfel-based fusion coupled with frequent model refinement through non-rigid surface deformations. Our approach applies local model-to-model surface loop closure optimisations as often as possible to stay close to the mode of the map distribution, while utilising global loop closure to recover from arbitrary drift and maintain global consistency},
author = {Whelan, Thomas and Leutenegger, Stefan and {Salas Moreno}, Renato and Glocker, Ben and Davison, Andrew},
doi = {10.15607/RSS.2015.XI.001},
file = {::},
isbn = {9780992374716},
issn = {2330765X},
journal = {Robotics: Science and Systems XI},
pmid = {397311},
title = {{ElasticFusion: Dense SLAM Without A Pose Graph}},
url = {http://www.roboticsproceedings.org/rss11/p01.pdf},
year = {2015}
}
